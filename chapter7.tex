\def\mychapter{VII}
\input{chapterhead}
\chapter{Language and semantics}\label{ch:semantics}
\section{Communication and norms}
\subsection{A problem about cooperation}
??cut:squeaking is better?

There are scenarios, such as the Prisoner's Dilemma or the Tragedy of the Commons??Refs, where it is difficult 
to see how to rationally secure cooperation between agents. The following should not be one of these. You have
two agents who will each in a separate booth choose whether to press a red button or a blue button. If they both
press the same button, they each get a reward, say a chocolate bar. If they press different buttons, they 
each get a penalty, say a nasty electric shock, with the penalty outweighing the award by a significant factor, so it's better 
to get neither than to get both. If either player omits to press a button, neither gets anything, and the buttons are so 
set up that one cannot press both. Moreover, the players are allowed to confer ahead of time.

Obviously, when conferring ahead of time, they will need to decide which button to press, by rolling a fair die or
flipping a fair coin if
necessary, and then they need to go into their booths and press that button. Neither has any incentive to defect
to pressing the other button, and there is no risk in pressing a button should the other defect fail to press
anything. This is a really easy win-win game. 

But now suppose our two players, Alice and Bob, are perfect expected utility maximizers who break ties with fair coinflips, 
and the only relevant utilities are the  rewards and penalties of the game. There are no further games that 
will be played. Nobody outside the game is in any way affected by the results (e.g., nobody will be disappointed 
if one of them breaks a promise). And because each player gets the same payoff, it won't matter whether Alice and Bob
maximize collective utility or their own personal utility. Finally, the above information is completely luminous to 
both players. I claim that at this point the obvious strategy---to decide on a button and then both press it---is no 
longer rationally available.

For concreteness, let's suppose that Alice and Bob have agreed to press the red button. They go into their booths. 
What will Alice do? She is a perfect expected  utility maximizer. She will only press the red button if the expected
utility of doing so is at least as big as that of all the alternatives (these being being pressing the blue button or 
pressing no button). Now the expected utility of pressing the red button is only going to be at least as big as the
expected utility of pressing neither button if Alice takes it to be significantly more likely that Bob will press red
the button than that Bob will press the blue button.\footnote{Suppose Alice maximizes only her own utility (if she
maximizes collective utility, just double all the utilities). Suppose $x>0$ is the reward and $-y<0$ is the penalty with
$y$  bigger than $x$ by a significant factor. Then the expected utility in pressing the red button will be $\alpha x-\beta y$.
Alice will only press the button if $\alpha x-\beta y\ge 0$, i.e., if $\alpha/\beta \ge y/x$. Since $y$ is bigger
than $x$ by a significant factor, this requires $\alpha$ to be bigger than $\beta$ by a significant factor.} 

But why should Alice take it to be significantly more likes that Bob presses the red button than the blue button? 
Ordinary human beings take themselves to be beholden to norms of promise-keeping, and tend to abide by those norms,
especially when there is no obvious benefit to failing to do so. But Bob is a pure expected utility maximizer. Whatever
normative force he takes promises to have has to be derivable from the norm of expected utility maximization. In ordinary
contexts, dealing with ordinary human beings, keeping promises certainly does maximize utility, because ordinary human beings
believe in norms of promise-keeping and punish those who break those norms (if only by castigating or refusing to enter on
joint projects with promise-breakers). But Bob is not dealing with an ordinary human being. He is dealing with an expected 
utility maximizer. 

Here is one way to see the difficulty. Imagine that Alice and Bob are perfect utility maximizers with a perverse value theory
that in addition to common-sensical value assignments to chocolate bars and electric shocks assigns non-instrumental negative value to keeping 
promises and non-instrumental positive value to doing the very opposite of what one has promised. I will stipulate that pressing the button of 
the other color counts as the ``very opposite''. In this case, if there is joint knowledge of the perverse value theory, it 
is more reasonable to expect Alice and Bob to press the button other than the one they promised. And now imagine that they are 
perfect utility maximizers with a value theory that assigns positive value to keeping promises and non-instrumental negative value
to doing the opposite. In this case, it will be more reasonable to expect Alice and Bob to press the button they promised. But 
then the in-between case, where Alice and Bob are perfect utility maximizers and assign zero value to promise-keeping and
promise-breaking, should be one where the probabilities of pressing the promised button and pressing the opposite button are
equal. 

What if we suppose that the solution here is that as a matter of contingent fact people have a preference for promise-keeping over
promise-breaking: we feel bad when we break promises and good when we have fulfilled them. Preferences enter into utilities,
and so if Alice and Bob have the standard preferences, they will have a bias in favor of promise-keeping, and if each knows the
other to have the preference, then each can take the other's preference into account, and hence each can expect the other to keep
the promise. 

First, it is not clear if this solves the problem if we imagine the penalty for mismatched button presses increased so that a preference
for avoidig the penalty is an order of magnitude stronger than the preference for promise-keeping. In that case, unless Alice and
Bob are going to be very confident in the other's choice, a preference for promise-keeping will not do the job.

Second, and more importantly, if a preference for promise-keeping is needed to solve the problem, we now have an argument that
some norm encumbent on humans requires such a preference. For if two human beings are stuck in a suboptimal solution in the button-pressing
game, they are clearly falling short of what humans should be able to achieve. The argument thus shows that there must be norms on human
beings that go beyond utility maximization, whether collective or individual.

\subsection{Arresting the regress of meaning}
Some communicative actions---speech acts or gestures---have their significance assigned through earlier communicative 
actions. Thus, sometimes one coins a word and stipulates its meaning in terms of other words, sometimes one uses gestures
to introduce a new word, and sometimes one just hopes that use in a rich enough communicative context will clarify the
meaning. But barring outlandish hypotheses such as that humans got their language from aliens, who got theirs from an
infinite regress of angels, we cannot suppose an infinite regress. There must be ur-communicative actions, ones which did not get
their significance from earlier communicative actions.\footnote{There is a Sellarsian objection to this. Perhaps there are 
behaviors prior to the advent of rationality that count as having communicative significance in virtue of \textit{later}
behaviors, in a kind of virtuous significance-conferring circle.??ref If so, however, then we can just count the whole circle 
of behaviors as the first ur-communicative community action.}

At the same time, there is a contigency here. While it feels natural to us to use an extended index
finger to indicate the nearest salient object approximately along the ray extending from the knuckle in the direction of
the fingertip, it would be possible to have rational beings that use this gesture to indicate the third-nearest salient
object along the ray extending from the index finger's tip to the knuckle. There is no necessary connection between the
physical behavior and its significance. We thus have a Mersenne question here: What explains the correlation between
physical behavior and significance in ur-communicative actions?

We might try to explain the correlation in terms of the actual contingent behavior of individuals and communities
which arises by natural or social selection. Suppose, for instance, that some social animals evolve to squeak at 
a certain pitch when observing a predator, thereby warning other members of their group. Eventually, their descendants
develop rationality, but the squeaking behavior is maintained, and remains correlated with the presence of a predator, even 
though it is now under voluntary and rational control. It is plausible to say that the squeaking is now a communicative
activity whose significance is ``Predator!'' 

But this plausible claim deserves more careful examination. Rationality complicates things. Suppose Alice sees a 
predator and is considering to squeak to trigger her groupmates' defensive behavior. If Alice's squeaking and her fellows' 
defensive behavior is to be rationally chosen, the agents need reasons. The fact that their ancestors used to squeak 
when predators were present and start defensive behavior upon such squeaking is an interesting bit of pre-history,
but there does not appear to be a reason for them to imitate this quaint custom. Even if we add the fact that they
find themselves with a desire to squeak in the presence of the predator and to initiate defenses upon hearing a squeak,
these desires at most generate the very weak kinds of reasons one has to fulfill miscellaneous subrational desires rather 
than the strong kinds of reasons that one has to warn one's fellows and protect oneself and one's cmmunity. 

There is no difficulty here if Alice is the only rational one, and hence the others will act on instinct. Alice can
then rationally squeak to trigger the instinct. Similarly, if Alice acts on instinct and the others are rational, they
can infer from her instinctive behavior that there is a predator present, as one infers fire from smoke. But when both
are acting purely rationally, we have a difficulty. Likewise, if Alice thinks there is a fairly high chance that her
fellows will follow their habit and prepare themselves, or if she knows that her fellows think there is a fairly high 
chance that Alice would find herself squeaking in the throes of instinct, there is no difficulty. The difficulty shows
up when we have nothing but rationality at play.

Perhaps we can solve the problem by positing a non-rational preference for squeaking when seeing a predator and for
preparing a defense when hearing a squeak? After all, arguably, even a perfectly rational being will act in accordance
with preferences when other things are equal. 

But the non-rational preference is insufficient here unless it is implausibly strong. For even if one finds oneself
with an urge to squeak in the presence of a predator, the squeak itself endangers one. Because of this, for a rational
being, the brute preference for squeaking is not sufficient to motivate the squeak. It is only when one thinks the
squeaking will trigger defensive behavior among one's fellows that it's worth squeaking. Similarly, we may suppose that
defensive behavior is costly and inconvenient, and is only worth engaging in, not withstanding the non-rational preference,
when there is reason to think there is an actual predator.

Instead of a brute preference, perhaps convenient priors will do. Thus, suppose that members of the community simply find
themselves with a high prior conditional probability that a member of the community rationally squeaks when presented with a 
predator and does not squeak when not presented with a predator.\footnote{I am grateful to ?? for the suggestion that
priors might do the job.} Knowing about that this prior is wide-spread in the community, Alice can squeak in order to 
get her fellows to update their credences in favor of a predator. The priors seem pleasantly self-confirming: if community
members have the priors, then it will become public that they do so, and the squeaking behavior will match the priors.

But now suppose Bob is reflecting on his convictions. Bob finds himself accepting a correlation between Alice's rational 
squeaks and the presence of predators. But since the squeaks are rational, there must be a rational explanation of these 
squeaks. Since we are no longer attempting a preference-based story, presumably the explanation is that Alice accepts a 
correlation between community members hearing squeaking and their rationally coming to think there is a predator. In other
words, Bob finds himself having a brute prior concerning a contingent and empirical matter---namely, another community
member having a certain credential state.  However, when we find out that our conviction about a contingent and empirical 
matter is simply a brute prior, that tends to undermine the conviction. Suppose that I find myself believing there is vast treasure buried under my house. I search
for the source of my belief, and find it's just a prior. Absent a story such as that angels put that prior in my head
to encourage me to dig out the treasure, finding out that this was \textit{just} a prior should undermine the confidence,
contrary to what subjective Bayesians think. 

Couldn't natural selection play the angel, though? There is an adaptive advantage to correlated priors in Alice and Bob 
that make communication possible, and these priors then end up automatically matching reality. ???

\subsection{Reason-generating mechanisms}
The transition from non-rational signalling to rational communication is thus difficult to analyze. We need some sort of 
a reason-generation mechanism.

Can we suppose that the reason-generation mechanism here is a necessary one? Perhaps it is a necessary truth that when
there is a pre-rational behavior that tends to be triggered by circumstances $C$, then that behavior when done rationally
\textit{signifies} $C$? But there would be multiple Mersenne questions that would be raised by such a necessary truth. First,
we need to select one item $C$ in the causes rather than another---does the squeak signify the predator's, or the
light in the air between the predator and the observer's eyes, or the immediate cause of the predator's presence? There are
multiple selection rules, no one of them significantly more natural than the others. Second, what reliability does the 
tendency have to have in order to yield a signification fact? ??more The parameters in the connection between behavior and
significance point to something contingent. We can imagine different species of rational beings where the parameters are
different from what they are in us. 

Reasons are normative entities. Thus a contingent reason-generation mechanism will, plausibly, be a mechanism for generating
norms. Aristotelian form fits well here. The form could directly specify that squeaking properly occurs only when there is a 
predator present, or it could specify a general rule for connecting pre-rational behavior with norms of significance. 

But even if there is such a norm-generating process, what makes the norms be norms of \textit{communication}? A cat's nature 
requires it to turn its ears towards relevant sounds. When we see a cat turn its ears in some direction, that provides us with 
evidence that there was some sound relevant to it. But the cat is not communicating that there is a sound relevant to it by
turning its ears. What, then, makes it be the case that a norm in the nature of a communicative animal is a communication-constituting
norm? Do we not need some further primitives besides norms of proper function to make it be \textit{communicative} proper function?

We can speculatively sketch a part of an answer in terms of the \textit{content} of norms. A toy story could be that 
some norms come in pairs, where one norm posits that a certain overt behavior is only proper when some fact $p$ is known to a 
community member to obtain and another community member is known to be present and capable of observing the behavior, and another 
norm posits that when that overt behavior is observed in another member of the community, there is a tendency to form a belief 
in $p$. In that case, the toy story says that a behavior that is a fulfillment of the first norm counts as a communication 
of $p$ and a behavior that is a fulfillment of the second norm counts as a reception of $p$. Of course, the full story would need
to be much more complicated.

And all that said, it is not clear that we need a full story as to which exact behaviors are in fact communications. What matters
for figuring out what to do is the content and force of the norms, not what kind of norms it is. It is a tautology that if the 
force of a norm is kept fixed, the norm has the same reason-giving impact on us, whether it be a norm of semantics, prudence, 
etiquette or morality. 

\section{Content and indeterminacy of reference}
Wittgenstein, Kripke, Quine and Putnam??refs have problematized reference and content in light of the fact that different
content attributions to our locutions can be made to fit with our behavior. The Wittgenstein-Kripke line of thought notes
that any finite number of cases of behavior can be made to fit with infinitely many rules. Any finite number of utterances
of ``$a+b=c$'' that fit with our ``usual'' interpretation of ``$+$'' will also fit with infinitely many rules, including,
say, the rule that ``$a+b=c$'' means that $c$ is identical with $a$ plus $b$ when $a$ and $b$ are less than or equal to $x$ and 
means that $c$ is identical with $a$ times $b$ when at least one of $a$ and $b$ is bigger than $x$, where $x$ is the largest
number we have ever discussed in the context of ``$+$''. The Quinean line of thought observes that the same word, ``Gavagai'',
can be interpreted to mean a rabbit or an undetached rabbit part, with both interpretations fitting equally well with the
community's practices. And finally the Putnamian line of thought observes that a remapping of the truth conditions can make
``The cat is on the mat'' mean any other true proposition, as well as noting that the identities of mathematical objects---such as
the integers---would be underdetermined even by a countably infinite number of statements about them.??ref ??expand-and-exposit

In all of these cases, we have the initial intuition that there is a well-defined meaning to the locutions, an intuition that
is destabilized by the arguments. These cases, thus, can be seen as the opposite of the cases of vague terms like ``bald'', where
our initial intuition is that there is no well-defined meaning.

We thus have two families of arguments. One family of arguments pushes in the direction of indeterminacy. And it does so not
just in the cases where indeterminacy is intuitive, as for ``bald'' and ``heap'', but alas also in cases where we expect determinacy,
as with the question whether we are referring to rabbits or undetached rabbit parts. Another family of arguments, mainly those
based on insistence on classical logic??backref, push in favor of determinacy, but alas also in cases where we expected indeterminacy.
If we want to maintain the determinacy of pretty much any term, then we will need to hold to something somewhat problematic---we will
need to bite the bullet by denying a premise of a relevant indeterminacy argument (plausibly, some variant of the Quinean argument 
applies to all terms). But similary if we want to maintain the indeterminacy of any term, we will have to wrestle with classical
logic. 

With regard to these arguments, it would be simpler either to embrace determinacy in all cases or to embrace indeterminacy in all 
cases. For then we would only need to bite the bullet on one set of arguments. If we are to do this, then embracing determinacy in
all cases seems preferable---embracing indeterminacy about all of language seems like it could undercut too much of our practices.
However, by treating all the cases alike, we go against common sense which distinguishes ``bald'' from ``rabbit''. 

The Aristotelian has a particularly good hope of having a metaphysical answer to the arguments for indeterminacy. This can be embraced
in all cases, thereby resulting a picture of a sharp world that we will discuss below, or only in some cases, which fits with 
common sense. 

The arguments for indeterminacy are all based on an assumption that the correct semantic theory will make semantic facts supervene on
facts about our actual behavior and the world around us. But we can reject this assumption, and add normative facts about humans 
to the facts about our actual behavior and the world around us as part of what the semantic facts supervene on. These further
facts could be hyperintensional normative
facts, such as that it is only appropriate to say ``Gavagai!'' in the presence of a rabbit. Granted, necessarily, one is in the
presence of a rabbit if and only if one is in the presence of an undetached rabbit part. But there can still be a difference between
the norm of its being appropriate to say ``Gavagai!'' in the presence of a rabbit and a norm of its being appropriate to say it 
in the presence of an undetached rabbit part.

For norms are hyperintensional: $\phi$ing and $\psi$ing might be such that necessarily one does one if and only if one does the other,
but it is still a different thing to be required to $\phi$ than to be required to $\psi$. One way to see this is that if one
is required to do something, one is required to try to do it. But trying, like intending and believing, is clearly hyperintensional.
It is a different thing to try to bisect or trisect an angle with ruler and compass than to try to bisect an angle with ruler and 
compass, even though, necessarily, one bisects or trisects if and only if one bisects, since trisection is impossible. If I do not
know that trisection is impossible and I have promised a friend to show them a trisection or bisection, what I am obligated to try
is different than had I promised to demonstrate a bisection. 
It is one thing to have a reason to bisect and another to have a reason to bisect-or-trisect. Or, to adapt an example of 
Faroldi's (??ref:p137, Hyperintensionality
and Normativity), you might be obligated to drive to the hospital, without being obligated to either drive to the hospital or 
drive to the hospital while drunk. 

The above examples all involve moral normativity. But plausibly the same is true of other kinds of normativity. The function of the
$\times$ key on a calculator is to multiply quantities, not to calculate the exponential of the sum of their logarithms. It is 
the proper function of a duck embryo to develop two feet, but  it is not the proper function of a duck embryo to grow a
number of legs that God would believe to be the smallest prime number.

Similarly, reasons are hyperintensional, and norms give rise to reasons, which makes it likely that the norms themselves are
hyperintensional. To see that reasons are hyperintensional, note that reasons sometimes provide explanations of actions, and 
explanations are always hyperintensional.\footnote{Cf. Faroldi (p.~139)??ref. Faroldi restricts this to non-causal explanations, but
causal explanations are also hyperintensional by our argument below.}
 That explanations are hyperintensional is easiest to see in the special case of entailing
explanations, where the explanans entails the explanandum (e.g., that Bucephalus is a horse and all horses are mammals explains
and entails that Bucephalus is a mammal). For if $p$ explains and entails $q$, then $p$ is equivalent to $p\And q$, but a 
conjunction does not explain its own conjunct. But if explanation were hyperintensional, then anything equivalent to an 
explanation would also be an explanation. But even without entailment it is easy to see the hyperintensionality of
explanation. For $p$ is equivalent to $(p\And q)\Or (p\And\Not q)$. But this complex disjunction does not explain $q$. 
For the second disjunct, namely $p\And\Not q$, does nothing to contribute to explaining $q$, and so if the complex disjunction 
explained $q$, it would do so by means of its first disjunct, $p\And q$, and that does not explain $q$. 

A similar argument may irectly shows the hyperintensionality of reasons. Suppose that $p$ is a reason for $x$ to $\phi$. Then 
$(p\And \phi(x))\Or (p\And \Not\phi(x))$ does not seem to be a reason for $x$ to $\phi$. For, plausibly, if a disjunction is a 
reason to $\phi$, then at least one disjunct is a reason to $\phi$. But $p\And \Not\phi(x)$ is not a reason to $\phi$: that I
promised to call you by noon and failed to do so is a reason to apologize, not a reason to call. And that I $\phi$ is not 
part of a reason for me to $\phi$, so $p\And\phi(x)$ is not a reason for me to $\phi$ either.

??add connective text??
Note that on our normative account we don't need any causal connection to the objects we speak about. Mathematical objects
are no more problematic than physical objects. Even if an infinite number of sets of mathematical objects satisfy the Peano axioms, it is open 
to the normative semanticist to say that there is a pair $(N,s)$ that make it be the case that according to the norms of our nature
saying ``There are infinitely many primes'' is appropriate just in case there are infinitely many members of $N$ that are prime
with respect to the successor function $s$, so that the members of $N$ are \textit{the} natural numbers. At the same time, the
normative semantics could allow that there is no privileged system $(N,s)$ but instead all mathematical statements are conditional.
Settling the question of which of these is true is difficult to task for the philosopher of mathematics, but neither presents a 
special semantic difficulty.

\subsection{Illocutionary force}
Typically, one asks someone for something that one wants. But asking is not the same as communicating one's desire. First,
sometimes one asks for something one doesn't want. For instance, a security specialist could conduct a phishing call where they
ask a fellow employee for their password, hoping that few if any will give it. Or a middle manager might be tasked by upper
management with requesting something from staff that the middle manager thinks is actually bad for the company, and hence hope
that no one will agree to the request. Conversely, one may want something but not ask for it for moral reasons. To adapt a 
situation that occurs twice in P.~G. Wodehouse stories??ref, one may own an ugly heirloom that one cannot give away because 
of one's relationship with the person from whom one received it, but one would be glad if it were taken away. One could imagine
a frank conversation where one happens to slip that one wouldn't mind the heirloom taken away. In the Wodehouse
cases, the communication \textit{is} a surreptitious request---and that, of course, is illegitimate, much as a king's
exclamation ``Would that someone rid me of this troublesome priest'' is an invitation to murder. But one could also imagine
a case where the slip is not a request, but simply a frank statement to a friend, followed by sincere emphasis that one isn't
requesting removal. In that case, removal of the heirloom would be theft, even if it were desired by the owner. Or, for a
different case, one might have a moral objection to a particular life-saving medical procedure, and hence one's conscience would
forbid one from requesting it, but nonetheless wish that the procedure were done to one against one's will, say by a medical
mistake, and one could in a frank conversation communicate that wish \textit{without} that constituting an underhanded request.

In making a request, one creates a reason for the other party to provide one with someone. And not just any reason, but a special
kind of reason in light of one's own request.???

But now consider the first time anybody ever requested anything. In requesting, they created a moral reason for their interlocutor. 
This was a power they already had, and the meaningfulness of the communicative act of requesting must have already been in place. 
How? How could that communicative act not only had its illocutionary force but been \textit{understood} to have that illocutionary 
force given that no one had ever requested anything? The meaning of a request is largely defined by the kind of reasons it gives
rise to. But how can one grasp these reasons if one has never encountered them before?

\section{Sharpness and levels}
\subsection{Sharpness at the second-level}\label{sec:limiting}
\subsubsection{Declarative practices and reasons}
We should all agree that it would be possible to have a communicative practice on which an declarative utterance instead of expressing 
a specific proposition subject to classical logic, expresses, say, a \textit{family} of propositions, and the utterance has the following
axiology: it is bad if none of the propositions is true, it is good if all of them are true, and it is neutral if some but not others are
true. We take someone to be engaging the communicative practice well (badly) to the extent that their utterances are good (bad).

We can complicate things in various ways. We might, for instance, make the family of propositions itself be fuzzy, in the technical sense that we assign
a degree (say between zero and one) to which a given proposition is in the family. Then we might say that an utterance is maximally good provided every proposition
even partly in the family is true, and maximally bad provided every such proposition is false. But for utterances on which there is no
such unanimity in the fuzzy family, we find a way of measuring an intermediate value, say by a count weighted according to the degree 
to which the proposition is in the family of the true propositions in the family minus the false ones. Thus, the family of propositions
corresponding to ``Alice is rich'' may contain to a high degree the proposition that she is at least a millionaire, to a low degree 
the proposition that she is at least a billionaire, and to zero degree the proposition that the sky is blue. 

And such practices are perfectly 
comprehensible within an Aristotelian framework: we can suppose that human nature makes some declarative utterances fulfill us, others
be contrary to our fulfillment, and others be indifferent to us.
I am not yet claiming that our practices are like that, just that practices like that are perfectly comprehensible.

However, it is very plausible that some of our everyday utterances are in fact not merely epistemically vague. An inquiry into whether three rocks can make 
a heap or exactly how much money one needs to have to be rich seems a waste of time, not only because the answers are useless to us, 
but because there is no answer. In particular, it is very natural to say with the supervaluationists that there are infinitely many 
ways to make ``heap'' and ``rich'' precise, for each of which there is a well-defined answer to the question, but without such
precisification there is no answer. This fits well with the hypothesis that our everyday communicative practices are  
like the ones described above. 

Our description of the practices presupposed that there are propositions that are simply true or false, and that given the truth
values of the propositions, the values of declarative utterances---whether just bad, neutral and good, or more fine-grained ones---are thereby
determined. However are they determined sharply, definitely? Isn't it plausible that not only is it vague whether some group of four rocks is a heap, 
but one can have a grouping of rocks---say, five of them---where it's vague whether it's vague or whether it's definite that it is a heap, so that 
it's vague whether the statement ``These rocks are are a heap'' is neutral or good (or it's vague what exact value it gets).

Now the value of an utterance gives rise to reasons. If an utterance has positive value, that constitutes a reason to make the utterance.
If it has negative value, that constitutes a reason to refrain from making it. And if it has no value, then we neither get a reason to make
it nor a reason not to make it. But now recall the argument from ??backref(and make cohere with this!) that moral evaluation is merely 
epistemically vague. If moral evaluation were more than epistemically vague, and yet we had classical logic, then the right account 
of that vagueness would be that there
are many moral concepts that fit with our usage of terms like ``is right'' and ``is wrong'', no one of which is privileged. But the 
central importance of morality to our rational lives requires privileging. Nothing can ultimately compete with moral wrongness as a reason
against an action. 

But what was true of moral concepts is \textit{a fortiori} true of reason concepts. Nothing can ultimately compete with \textit{reasons} in
guiding our lives. Just as we might say that the overridingness of morality is the central discovery of ethics---explicit in Socrates---the 
centrality of reasons is the central discovery of action theory. It is difficult to say more here than to bang one's fist on the table. 
The concept of a reason is not an unprivileged one among many closely similar concepts. And this undercuts the possibility of 
non-epistemic vagueness about reasons. But because of the way the good and the bad immediately give rise to reasons, it follows that
they cannot be vague either. And hence in the supervaluationist social practices described above, where declarative utterances express a 
family of precisifying propositions, there must always be sharp facts about whether the family is such that all, none or merely some of its
members are true. In other words, vagueness must stop at the first level.

A reason-giving practice can only generate sharp reasons, since there are no others. Thus if vagueness is somewhere involved in a 
reason-giving practice, that vagueness must be ``flattened out'' once reasons are generated. Depending on the details, there may be
more than one way of doing that. For instance, plausibly there is first-level vagueness about a person's height: there are multiple 
ways of measuring wihtout any privileged one, depending on how much upward stretching is allowed, what gravity regime the measurement 
is made in (remembering that even on earth, gravitational acceleration varies about half a percent with location), whether skin flaking 
at the top of the scalp is included, etc.  A practice that rewards the ``tallest person'' (say, a Guinness World Record practice) might
generate a reason to bestow the reward on a person who is definitely the tallest, or on one who is definitely or vaguely the tallest, or
it could (likely unfairly) flatten the vague data about height into sharp facts about reasons in some more complex way, especially if
the family of precisifiers of ``$x$ is the tallest person'' comes along with a degree-of-membership function. 

In principle, any finite number of levels of vagueness could also get so flattened out. Thus, if there is second-level vagueness but no third-level
vagueness, one might specify that there is reason to give the reward to someone who is definitely definitely tallest or 
definitely vaguely tallest or vaguely definitely tallest, and to no one else. And then we have fully sharp reasons, since there will 
always be a definite fact of the matter whether there is a reason to give the reward absent third-level vagueness. In light of this,
one might think that the sharpness of reasons argument would allow declarative practices corresponding to any finite number of levels
of vagueness. A limitation of vagueness to a finite number of levels would itself be a significant result. 

However, there is reason to hold out for one level of vaguness in our declarative practices. The most plausible account of the flattening in 
our ordinary declarative practice $d$ is:
\ditem{def-declare}{There is $d$-reason to declare $p$ if and only if $p$ is definitely true.}
Moreover, the rule \dref{def-declare} itself seems definitely correct. Thus, if the existence of a $d$-reason is a definite matter,
then whether $p$ is definitely true must be a definite matter. And if definiteness is definite, so is vagueness, since, definitely,
$p$ is vague if and only if neither $p$ nor $\Not p$ is definite. Thus vagueness stops at the first level.

The main competitor to \dref{def-declare} would be:
\ditem{def-declare-vague}{There is $d$-reason to declare $p$ if and only if $p$ is definitely or vaguely true.}
Given that \dref{def-declare-vague} would give us reasons to affirm evidently contradictory sentences in cases of vagueness, 
it is not very a plausible candidate for an account of the relation of $d$-reasons to truth. However, even if \dref{def-declare-vague}
were the correct account, as long as it was definitely the correct account, the sharpness of ``There is $d$-reason to declare $p$''
would imply the sharpness of ``$p$ is definitely or vaguely true''. Now, it is definitely true that 
\ditem{dv-d}{$p$ is definitely or vaguely true if and only if $\Not p$ is not definitely true.}
Hence, we would have sharpness of ``$\Not p$ is not definitely true'', and hence we would have sharpness of ``$\Not p$ is definitely
true''. But since it's definitely true that $q$ is definitely true if and only if $\Not\Not q$ is definitely true, letting $p$ be
$\Not q$, we conclude that we would have sharpness of ``$q$ is definitely true''. Since this would work for all $q$, we would again
have sharpness of definiteness and of vagueness in general.

One might try for some other flattening of vagueness profiles to reasons. But \dref{def-declare} and \dref{def-declare-vague} seem to 
be the most plausible two candidates. Thus we have good reason to stop at first level vagueness.

Finally, we might also argue for the claim that vagueness stops at the first level by thinking about the specifics of the morality of promises. If I promise
to $\phi$, and I do in fact $\phi$, then I have done morally well; if I do not in fact $\phi$, then I have done morally badly.
But what if it's vague whether I have $\phi$ed? Let's say that I have promised to cure your baldness, and because of my treatment
you have some meager tufts of hair that you didn't have, not enough to make it definite that you are non-bald and yet not enough
to make it definite that you are bald. Did I do well or badly? Well, it is very natural to say: my activity was neutral in respect
of the promise. Given a sharpness in attribution of moral goodness, badness and neutrality, and given the above plausible matching
of moral value with attributions of definite truth, definite falsehood and vagueness, we have good reason to think that in the case
of predicates that can figure in promises at least, we can at most have first-level vagueness---it must be sharp whether someone is
definitely bald, vaguely bald or definitely non-bald. But if we have second-level sharpness about baldness, plausibly we have 
second-level sharpness about everything.

\subsubsection{Logic}
A standard argument for full-blown epistemicism is the Sorites series.??Sorensen
Consider this argument, where the if-then statements are material conditionals.
\begin{itemize}
\item[$(P_0)$] Charles wasn't old on his first day.
\item[$(P_1)$] If Charles wasn't old on his first day, he wasn't old on his second day.
\item[$(P_2)$] If Charles wasn't old on his second day, he wasn't old on his third day.
\item[...] \ {}
\item[$(P_{26999})$] If Charles wasn't old on his 26999th day, he wasn't old on his 27000th day.
\item[$(C)$] So, Charles wasn't old on his 27000th day.
\end{itemize}

Clearly $C$ is false: a 73-year-old \textit{is} old. The argument, however, is valid by 
a sequence of $26999$ instances of \textit{modus ponens}. The only way a valid argument
can have a false conclusion is by having a false premise. Now, premise $P_0$ is clearly
true. Thus, at least one of the premises $P_n$, for $n=1,...,26999$, is false. 

Now, if $P_n$ is false for $n\ge 1$, then since $P_n$ is a material conditional, its 
antecedent is true and its consequent is false. Thus, Charles wasn't old on his $n$th
day but became old by his $(n+1)$st day. Hence, we have a one-day transition from 
young to old. And it is precisely such sharp transitions that non-epistemicist advocates
of vagueness reject as absurd.\footnote{We should assume that by ``old'' we mean something like
``calendrically old''. For we all understand such locutions as ``Alice became old the
day she found out she had lung cancer.''} Yet logic forces us to accept them.

On the view I am defending, logic applies to propositions, not to 
sentences of our declarative practices. If we consistently precisify the premises and conclusion
of the argument, the precisification of one premise will turn out to be false.\footnote{Only one. For if Charles is old
on a day, he's old on all subsequent days. If $P_n$ is false for $n\ge 1$, then the consequent
is false, so Charles is old on his $(n+1)$st day, and if $P_0$ is false, then Charles is old on
his first day. Either way he is old on day $m$ whenever $m>n$, and
so $P_m$ is true, since it's a material conditional with false antecedent. Thus, as soon as one
premise is false, all the subsequent ones must be true.} 

Sticking to the sentences in the argument, we can say that $P_n$ is definitely true for small $n$,
then becomes vague (maybe somewhere around $n=22000$), and finally becomes definitely true again. 
The points at which $P_n$ becomes vague and then again definitely true are fully precise, which is 
counterintuitive, but that counterintuitiveness is less evidentially significant than the 
violation of common sense in Charles becoming old on a specific day.

If we think a sentence is bad to say when definitely false, neutral when vague, and good when
definitely true, then none of the $P_n$ are bad to say, but the conclusion $C$ \textit{is} bad
to say. We might think that this means that we have a case where something bad to say logically
follows from a number of things that are not bad to say, and this may seem absurd. But
it's not clear that this is absurd. For we are not here dealing in propositions, where a conjunction
of acceptable ones is also acceptable, but with sentences in a vague declarative practice. We should
not import logical intuitions that apply to propositions in thinking about the value of a declarative
practice. It may also help to see that in the case of \textit{moral} badness there is nothing particularly
paradoxical about cases where asserting a conjunction is bad but no conjunct is bad to assert. For instance,
consider the case\footnote{Not hypothetical.??ref} of a racist who writes a series of 
factually correct articles, each one about a highly immoral member of a minority group. Each
article may be such that it is not bad to write, but the oevre as a whole is racist. 

We do, however, have a famous difficulty. Like other supervaluationist views, the account being
defended has the consequence that definitely:
\ditem{some-trans}{There exists $n$ between $0$ and $27000$ such that Charles is not old on day $n$ but is old on day $n+1$.}
At the same time, for any specific day $m$ in that range, say $m=22003$, it is \textit{not} definitely true that:
\ditem{m-trans}{Charles is not old on day $m$ is but is old on day $m+1$.}
In particular, the disjunuction of instances of \dref{m-trans} as $m$ ranges over all the numbers between $0$ and $27000$
is definitely true, but every disjunct is merely vague. This is, admittedly, counterintuitive. This counterintuitiveness
is, I suspect, tied to the fact that if we have a true disjunction of propositions, at least one disjunct is true....????



??bite bullet on exists $n$, but ok as logic doesn't apply

\subsubsection{Some objections}
The conclusions above are counterintuitive. Intuitively, just as it sounds silly to think that on such-and-such a day it was true
to say that Elizabeth~II was (chronologically\footnote{It is perfectly comprehensible to say that someone \textit{psychologically} 
became an old person after some traumatic event.}) old while it wasn't true to say it a day earlier, it sounds silly to say think
that there was a precise day on which she was definitely old, while the day before she was merely vaguely old, and similar objections
can be made at higher levels of vagueness.

However, our linguistic intuitions are typically more trustworthy than our metalinguistic intuitions. Thus, our intuition that oldness is
can be vague is more to be trusted than our intuition that vagueness can be vague. We have good arguments for second-level sharpness, and
these arguments undercut the intuition.

A second objection starts like this. Communicative practices of a declarative sort that embody first-level vagueness are indeed possible. All we 
need to do is to specify the values in the way we did at the beginning of Section~\ref{sec:limiting}, so that an utterance is 
good when all the propositions in an associated family are true, bad when they are all false, and neutral otherwise. If we had
a community of perfectly sharp speakers, we could even imagine introducing such a practice, either as a sort of pleasant relaxation
(it's not fun to always have to be precise) or for practical reasons, to be engaged in at times. Suppose we have such a practice, and it
includes terms like ``hairs'' and ``scalp''. But then we could engage in this practice to introduce a new non-sharp
communicative practice. For instance, we might specify that in the new practice a predication of ``is bald'' is good when 
the person has more than 2000 hairs on their scalp, is bad when the person has fewer than 1000, and is neutral otherwise. However, 
how much filament  needs to stick out of a follicle for the follicle to count as hosting a hair itself appears to be fodder for 
first-level vagueness matter, and it can be first-level vague whether a hair is on the scalp or the upper part of the cheek.
Consequently, in the new practice we can have cases where it's vague where Jim's crinal profile falls---whether he has fewer than 
1000 hairs on the scalp, more than 2000, or in-between. And in such a case it may well be vague that it's vague whether he is bald.

Now, given the possibility of such a practice, its actuality is likely. Surely we often do extend our communicative practices,
using old---and presumably vague---terms to introduce new ones. And we do that with our vocabulary.

However, notice that the quick sketches of communicative of social practices corresponding to vagueness were accounts of declarative
practices. One does not introduce a new social practice---a game, say---by an declarative practice, but by an
institutive practice: ``Let's a play a game with rules $R_1,...,R_n$.''\footnote{Though of course one might
use declarative grammar: ``We will play a game with rules $R_1,...,R_n$.''} 

While the norms of a declarative practice that includes vague utterances is easy to sketch, it is more difficult to sketch those of 
an institutive practice that involves vagueness. The rules of a practice provide reasons for the practitioners. But if
it cannot be vague whether something is a reason for $\phi$ing, a reason against $\phi$ing, or neither, then we cannot make it
vague what the rules defining the practice are and how they apply. What we can do is at most something this. We can have a practice 
of instituting practices, where we specify a collection of ordered ``rule'' pairs $(D,E)$ where $D$ is a description of a behavior (or maybe situation) and $E$ is an in-practice evaluation, such as ``permissible'' 
or ``bad'', and where the description $D$ is such that $D(b)$ is a declarative utterance of a linguistic practice embodying first-level 
vagueness when $b$ is a name of a behavior. Our practice of instituting practices then specifies that if $b$ falls under $D$, where
$(D,E)$ is one of the rules then, $D(b)$ is definitely true if and only if $b$ has $E$.
In cases where $b$ does not definitely fall under the description $D$ in any of the rules, then we can simply say that $b$ definitely
lacks all of the relevant evaluative properties. 

For instance, the rules for an oversimplified race $r$ could be $(A,W)$, $(B,T)$, and $(C,L)$, where $W$ is a win, $T$ is a tie, 
and $L$ is a loss, and $A(r)$ says that $r$ is a performance that is a run with the upper body of the runner crossing the finish
line before the upper body of any other runner, $B(r)$ says that $r$ is a performance that is a run with the runner's upper body never
crossing the finish line or another runner's crossing earlier, and $C(r)$ is the denial of $A(r)$ conjoined with the denial of $B(r)$.
Now suppose that in our first-order declarative language, sentences like ``Alice's upper body crossed the finish line at $t$'' are vague
when what crossed the finish line at $t$ was a loosely attached scab on the forehead. Then in cases where Alice was ahead only by such
a scab, Alice definitely lacks a win, a tie or a loss. If a win and a tie have positive valence, while a loss has negative valences, then
we can say that Alice's performance definitely is neutral.

That all our games are in fact perfectly sharp in their values is counterintuitive. But it is hard to avoid this conclusion while holding 
on to the privileged role that reasons play in our lives that forces reasons to be sharp.

\subsubsection{A sharp world and a fuzzy language}
A broadly-held intuition is that the world is sharp but our language is fuzzy, so all the vagueness is due to our language.
There is a well-known objection to this: our language is itself a part of the world, so linguistic vagueness is still vagueness
about the world. 

The view defended above where vagueness is restricted to the first level does justice to the sharp-world-fuzzy-language intuition. 
Our declarative sentences express a range of propositions, maybe even a graded range, and that's the 
fuzziness of the language. However, the propositions in the range are themselves sharp, and the truth of the sentences is
derivative from the truth of the propositions, so ultimately the world impacts our language through the sharp end of our
practices, and the world itself can be said to be sharp. 

At the same time, the view manages to escape the objection that our language is a part of the world. The relevant part of the world
is our declarative practice. And the semantics and norms of this practice are fully sharp. There is always a definite answer to 
the question whether a given proposition is a precisification of a given declarative sentence, to what degree (if the account 
involves degrees), and what the norms governing the use of the sentence are. It can be vague whether a sentence is true, but it 
is not vague what the sentence means: it means its set of precisifiers. 

Requiring a piece of sports equipment to be between exactly $200$ and $250$ grams does not render a sports practice vague.
Similarly, the fact that the evaluative properties of our declarative language are sometimes defined in terms of ranges of propositions,
rather than individual propositins, does not make the practice itself vague. Linguistic vagueness on this view does not mean that
linguistic practice as a practice is vague. It just means, very precisely, that some of the sentences of the language express a range
of propositions. This kind of vagueness does not make the practice itself vague, and does not introduce any vagueness into the world.

On the other hand, if there were higher-level vagueness, so that sometimes it was vague whether a sentence is, say, definitely true,
the linguistic practice as such would be vague. For the practice depends normatively on whether a sentence is definitely true:
there is a practice-internal good to declaring a sentence that is definitely true which is not had when one merely declares a sentence
that is vaguely true. 
??Merricks

A closely-related intuition is that the world as it objectively is is sharp, but the world as it is relative to us is fuzzy.
Someone who accepts this intuition may insist that practice-internal values are themselves relative to us, rather than a part
of the objective furniture of the world. Again, this is a difficult line of defend given the observation that if something has
a practice-internal value for some individual $x$, then it is an objective fact about the world that it has that practice-internal 
value for $x$. 

Perhaps, however, one could read this intuition as implying that there is second-level vagueness but no third-level vagueness.
Thus, one might say that for our declaratory practice, it is not sharp whether a performance is good, neutral or bad, but 
there is some objective range of precise interpretations of that practice, and we say that a performance is definitely good 
provided it is good on all interpretations, vaguely good if good on some but not all, and definitely not good if good on none. 
What that range is, however, is an objective fact about the world. Within each interpretation, the evaluation of a performance 
will be sharp. However, there does not seem to be any significant philosophical benefit to placing the sharpness at the third-level
rather than the second. We are left with the problematic idea that the concept of a reason is subject to multiple precisifications, 
in a way that does violence to the overridingness of rationality, and besides we have a more complex view, while still requiring
an account of the third-level sharpness, which is no easier to have than an account of second-level sharpness. And the intuitions
supporting second-level vagueness are just not as robust as those supporting first-level vagueness.

\section{A neo-Aristotelian account}
The neo-Aristotelian account allows us to have a completely sharp world with our language being completely sharp, with there being
definite facts of the matter about significant and insignificant
questions: Is Alice dead yet? Is this pile a heap? Should Alice rebuke Bob publicly? Is the smashed object a car?
Is this still the ship that Theseus sailed in? Is Beethoven a better composer than Bach? Should I lower my credence in quantum
mechanics after the mildly senile retired physicist told me she just found a contradiction in it? Is a cat a dommal (where ``dommal''
is a term whose patterns of use are that users are content to call all dogs ``dommals'' and infer mammality from being
a dommal). 

Our nature \textit{could} provide us with this sharpness. First, when the propositions in turn are concern normative matters, our 
form can at least partly ground the truth values. This can yield complete sharpness about all normative matters.

Second, our nature could ground the facts about the proposition expressed by and illocutionary force of each of our utterances 
by grounding the norms that specify how facts about our symbolic behavior together with facts about the non-symbolic aspects of the world attach 
propositions and illocutionary force to utterances. These rules could be very complex, and known by us only approximately and in general
terms. 

But at the same time, instead of grounding the specific proposition expressed by each utterance, our nature could ground facts 
about ranges of propositions, thereby allowing declarative utterances to be vague with multiple precisifiers. Again, our nature 
can do this by fully precisely grounding our semantic norms---for, as we saw in ??backref, it is possible to have fully precise
semantic norms and yet genuine first-order vagueness.

??blunt language and sharp world


%https://johnmacfarlane.net/fuzzy-epistemicism.pdf
??backref to indeterminacy

\section{Norms of assertion}
Under what conditions may we assert a proposition $p$? The literature contains a number of answers, of which the main 
three are that you believe, justifiably believe and know $p$.??ref\footnote{There may also be some edge cases where none 
of these seem right. For instance, suppose that you are temporarily deafened after an accident and you do not even know whether 
you still have the power of speech. You turn to a friend and try to say: ``At least I can still speak!'', and gauge from 
their reaction whether what you said was true. In that case, you don't believe or know that what you are saying is true, but 
if you do succeed in speaking, it \textit{is} guaranteed to be true, so you are not being dishonest. Handling such cases in 
an account of the norm of assertion is difficult. It is tempting to modify suggested norms to say that you believe, 
justifiably believe or know the conditional that if you succeed in asserting $p$ to your audience, then $p$ is true. But it is 
not clear that in ordinary assertions you need to have any beliefs about such complex conditionals.??ref:Pruss These complications
would only serve to strengthen my case for the presence of Mersenne problems, and so I will simplify the discussion by ignoring them.}

To a Bayesian who thinks that belief and justification always come in degrees, all three norms come with an implicit or 
explicit threshold of the credence and evidential levels at which assertion becomes appropriate. And then we have a 
Mersenne problem: what explains or grounds why the threshold is where it is.

A non-Bayesian might think that belief, justification and/or knowledge are binary distinctions that cut the epistemic 
world at the joints. If so, then it may seem that we have no Mersenne problem for assertion, and indeed the lack of the 
problem is an advantage over Bayesian approaches. However, the problem returns when we take into account the complexity
in real-life assertions. For the level of belief and/or justification needed for an assertion does in fact vary from case to 
case, depending on context and confidence markers. 

Expert witnesses speaking under oath need to be more confident of what they are asserting than friends tossing around 
ideas over a beer, with a vast amount of contextual variation in between. A realistic account of the norm of assertion 
needs to take such context into account. Furthermore, even when we keep context fixed, our tone of voice, body language (including
facial expression), and choice of wording communicates the level of confidence. While one might not be lying if one says something that one 
just barely knows with a voice communicating the kind of justified confidence that a mathematician has in theorems verified
by referees, one is violating the norms proper to asserting with that tone of voice. 

It is clear, thus, that a realistic account of the norms of assertion will have to involve functions from pairs $(C,S)$ 
where $C$ is the conversational context and $S$ is the speaker cues to the degrees of belief, confidence, justification 
and/or knowledge relevant to assertion. These functions are unlikely to admit of any simple mathematical expressions.
Even if we neglect the social complexities of context, speaker cues themselves involve at least the three dimensions of 
tone, body and wording, weighed in a complex way. Yet it is clear that we have norms here---and indeed morally relevant norms---and we need an 
answer to the question of what grounds the functions involved in the norms being as they are.

It is plausible to say that the functions here are largely socially defined. The same tone of voice in one culture may 
convey confidence and in another something quite different. However, that only shifts the Mersenne problem. If previously
we were, say, trying to find a ground for a function $f$ from context-cue pairs to required degrees of belief, we now need
a grounding for the (second-order) function $g$ that assigns to a set $R$ of relevant social regularities a ``threshold function'' $f=g(R)$ 
from context-cue pairs to required degrees of belief. Slight reflection should show that our function $g$ can be expected to 
be rather complex. 

We cannot say, for instance, that the degree of confidence $f(C,S)$ required for a context-cue pair $(C,S)$ 
is the average amount of confidence in fact occurring for $(C,S)$ in a culture with regularities $R$. Presumably,
the majority of assertions in a culture are appropriate. And among the appropriate assertions, most not only meet
the required threshold of confidence for their context-cue pair, but likely exceed it at least slightly. This 
suggests that it should be at least possible in a culture that the average level of confidence for asserting in 
the case of a given context-cue pair is higher than the minimum required level, and so we cannot define the 
threshold as the average. 

We would likely be closer to correctly predicting the mark of the threshold if we set the threshold some ways below
the average, say specifying that we should be one standard deviation below the 
average level of confidence. But that would likely lead to a Mersenne problem: Why is it one standard deviation below 
the average, instead of some other statistically attractive measure, such as being at the 25th percentile level of 
actual confidences for those context-cue pairs. Furthermore, such formulas are likely to fail in a hypothetical 
society where everyone is perfectly honest, and hence always asserts at or above the required threshold of confidence.

Further complexities arise from local (spatial, temporal and other) variation in cultures, even that between neighborhoods 
in a single city. The 
sample sizes for the local regularities $R$ are likely to be small, and the function $g$ from regularities to 
threshold-functions will need to take into account both local and non-local regularities, with some sort of a weighting 
in favor of the local ones. This is likely to be quite complex, and the Mersenne question of the explanation of 
why this exactly function---doubtless with many apparently arbitrary parameters---is the one that governs our 
assertive behavior is indeed a very pressing one. 

The Aristotelian, however, can embrace the complexity, and say that the human form specifies the function from social 
regularities to threshold-functions. 

\section{$^*$Natural numbers}
Very plausibly:
\ditem{number-truth}{any first-order statement about natural numbers and their arithmetical operations is determinately true 
or determinately false, whether or not we know its truth value.} 
But what is true of the natural numbers and their arithmetical operations will frequently be false of other sets of mathematical
entities with their operations. One may initially conclude from \dref{number-truth} that we are thus able to gain unambiguous
reference to \textit{the} natural numbers and their operations in our language or thought, and then we will have a puzzle as 
to how we manage to pick out the natural numbers from among the infinity of mathematical objects.

But that's too quick. We learn from Benacerraf??ref that the concept of \textit{the} natural numbers is dubious. Set theorists
frequently identify the sequence $0,1,2,...$ of natural numbers with the sequence of sets $\varnothing, \{\varnothing\},
\{\varnothing, \{\varnothing\}\},...$ (i.e., identify $0$ with the empty set, and then identify each number with the 
set of its predecessors). It is implausible to think that this strange set-theoretic construction captures 
\textit{the} natural numbers, but it does capture a structure that for all practical purposes behaves (with appropriately
defined operations) like them. But other sequences could be used equally well. For instance, we might 
go for the sequence of sets $\varnothing, \{\varnothing\}, \{\{\varnothing\}\},...$. Or, following Frege??ref, we might 
identify a number $n$ with the class of all sets with $n$ elements. 

Suppose we take the lesson from this to be that there is no such thing as \textit{the} natural numbers. There will still be 
``arithmetical truths'' and ``arithmetical falsehoods''. There is still no reasonable doubt about the truth of the magnificent ancient
Greek discovery that for every prime number there is a larger prime number, or that Goldbach's Conjecture that every even
number bigger than two is the sum of two primes is either true or false. It remains highly plausible that \dref{number-truth}
is correct, even if there is no such thing as \textit{the} naturals. This requires that even if we do not pick out a 
specific sequence of naturals with their arithmetical operations, our language or thought somehow manages to characterize
a ``natural number structure''---an infinite plurality of objects with appropriate arithmetical operations---with sufficient
determinacy to fix the truth value of any first-order statement about them.

But how do we do that? Taking a cue from Euclid, one might say that we characterize natural number structures by a collection
of axioms. For instance, we might think of natural numbers in terms of a ``successor'' operation, and begin by saying that every natural number has a successor and no two numbers have the same successor, and continue on through our favorite axioms, such as 
the Peano ones. The problem with this is that G\"odel's first incompleteness theorem says that any consistent recursively expressible 
axiomatic characterization that includes the obviously true Peano axioms is insufficient to determine all the truths about natural numbers, and hence will fail to yield \dref{number-truth}. For any such axiomatic characterization, there will be a pair of 
mathematical structures, $N_1$ and $N_2$, each of which satisfies the characterization, and an arithmetical statement $p$ that 
is true of $N_1$ but false of $N_2$. 

There are several known solutions to this problem. The first is to simply deny \dref{number-truth}, and allow a genuine 
indeterminacy to some arithmetic statements, which are neither true nor false. This is counterintuitive, but if we could 
ensure that only very strange arithmetical statements have that indeterminacy, it could be acceptable. Unfortunately, we 
cannot ensure this. 

Consider statements of the form
\ditem{provability}{$Q$ can be proved from $P_1,...,P_n$}
where $P_1,...,P_N$ and $Q$ 
are sentences of first order logic. Such ``provability'' statements are not particularly strange, and I think we find ourselves
with strong intuitions that for any $P_1,...,P_n$ and $Q$, there has to be a determinate fact of the matter about whether 
\dref{provability} holds. This claim seems close to the heart of the objectivity of logic. But as G\"odel famously noted, sentences
can always be encoded as numbers, and the provability relation can be encoded using arithmetic operations and quantifiers. 
As a result, \dref{provability} is equivalent to an arithmetical statement. 

Suppose now that we restrict \dref{number-truth} to arithmetical statements that are translations of provability statements.
Can we now characterize natural numbers in a finite first-order way that is sufficient to yield the truth values of these 
(translations of) provability statements? Again, the answer is negative, but the issue is more complicated. Consider some 
set $A$ of first-order recursively specifiable consistent axioms including enough axioms of arithmetic. Let $G$ be a Rosser-tweaked
G\"odel sentence for these axioms, chosen so that $G$ is a $\Sigma_1$ sentence, i.e., has only one unbounded quantifier, 
which quantifier is existential??refs. Thus, $G$ is of the form $\exists n F(n)$, where all the quantifiers in $F(n)$ are 
bounded, i.e., of the form $\exists m (m<k \And ...)$ or $\forall m(m<k \rightarrow ...)$. We can now construct a Turing
machine $M_G$ which iterates through all the natural numbers $n$, and halts as soon as it gets to $F(n)$. Thus, this Turing machine
halts if and only if $G$ is true. But a statement that a specific Turing machine $M$ halts can be translated into a statement
that a certain formula $\phi_M$ of first-order logic is valid, i.e., is provable from a tautology.??ref Putting all this together,
and assuming our collection of axioms includes enough arithmetic to make the argument go, we will be able to prove from the 
axioms in question that $\phi_M$ can be proved from one's favorite tautology if and only if $G$. Since $G$ is neither 
provable nor disprovable from $A$, we thus have a provability statement that is neither provable nor disprovable
from $A$.

Thus, even if we restrict the arithmetical truths we want definite truth values of to the translations of provability
statements, we won't be able to give a recursive characterization of first-order axioms that yield the truth values.

There is, however, an Aristotelian solution to the problem. While a finite collection of first-order axioms is insufficient 
to characterize all arithmetical truths, an infinite one can easily do so (if one is really profligate, one can just include all and only the arithmetical truths among the axioms!). We already saw in previous chapters that the human form likely has a vast
dizzying collection of norms embedded in it. Why not an infinite collection? Thus, human nature could include infinitely many arithmetical norms, such as ``One should use arithmetical concepts in such a way that it is appropriate to think that $A_n$'' (or, alternately, one can have a linguistic version of this norm about what kinds of things it is appropriate to say), where $A_n$ is the $n$th of the axioms, and where the axioms $A_1,A_2,...$ are sufficient to determine the truth value of all arithmetical statements (or maybe just of all 
provability statements---i.e., all of $\Sigma_1$).

The Aristotelian solution is not the only one, of course. We might have a Platonic solution on which, \textit{pace} Benacerraf,
there really is a privileged collection of \textit{the} naturals in the Platonic heaven, distinguished from alternatives by 
something like greater ``naturalness'' in the Lewisian sense (??ref). Or we might accept causal finitism??ref,
whcih builds the concept of the finite---and hence of a natural number---into the metaphysics underlying causation.(??ref) 
Or we might simply suppose a ``magical'' theory of reference on which there is a special relation between the human 
mind and a certain collection of mathematical entities.cf.??refs 

Nonetheless, the present Aristotelian solution has a certain attractiveness. Unlike the magical theory of reference, we do not need 
to posit anything new about us---just more in the way of norms. And unlike the Platonic or causal finitist solutions, the
Aristotelian solution does some justice to the intuition that mathematical terminology is stipulated by our minds---except 
that the stipulation of the axioms of natural numbers is built into the nature of the human mind, rather than merely contingent.
Furthermore, the Aristotelian solution allows for an epistemology of mathematics that is closely akin to the epistemology 
of ethics, where we know norms by having an intuitive though fallible tendency to follow them, and so a particular axiom of 
arithmetic can be accessed by our finding ourselves inclined to use arithmetical concepts in accordance with the norm encoding
the axiom.

\chaptertail

