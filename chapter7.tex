\def\mychapter{VII}
\input{chapterhead}
\chapter{Language and semantics}\label{ch:semantics}
\section{Communication, norms and illocutionary force}
\subsection{Cooperative games}
There are competitive games, such as the Prisoner's Dilemma or the Tragedy of the Commons??Refs, where it is difficult 
to see how to rationally secure cooperation between agents. Cooperative games, on the other hand, seem like
they should be much easier. Say, you have
two agents who will each in a separate booth choose whether to press a red button or a blue button. If they both
press different buttons, they each get a reward, say a chocolate bar. If they press the same button, they 
each get a penalty, say a nasty electric shock, with the penalty outweighing the award by a significant factor, so it's better 
to get neither than to get both. If either player omits to press a button, neither gets anything, and the buttons are so 
set up that one cannot press both. Moreover, let us suppose, the players are allowed to confer ahead of time. Here is an
example pay-off matrix:

\begin{center}
\begin{tabular}{ cccc }
\hline
    & red & blue & nothing \\
red & -10,-10 & 1,1  & 0,0 \\
blue & 1,1 & -10,-10 & 0,0 \\
nothing & 0,0 & 0,0 & 0,0 \\
\hline
\end{tabular}
\end{center}

Obviously, when conferring ahead of time, they will need to decide which button each should press, by rolling a fair die or
flipping a fair coin if
necessary, and then they need to go into their booths and press that button. Neither has any incentive to defect
to pressing the other button, and there is no cost to pressing a button should the other fail to press
anything. The game has three Nash equilibria, pairs of strategies such that neither player would gain from
changing their strategy while the other player's remained fixed: red-blue, blue-red and nothing-nothing. In 
the terminology of David Lewis's pioneering study of coordination games??ref, each of these is also a coordination 
equilibrium, namely a pair of strategies such that no player would benefit from any one player's (their own or the other's) change of strategy. While Lewis's primary interest was in the mechanism (e.g., convention) by which we can land
in \textit{a} coordination equilibrium, my interest here will be in how we can land in one of the better two equilibria,
red-blue or blue-red, instead of falling into a safe scenario where both players avoid risk by pressing no button. 

Suppose our two players, Alice and Bob, are perfect expected utility maximizers who break ties with fair coin-flips, 
and the only relevant utilities are the  rewards and penalties of the game. There are no further games that 
will be played. Nobody outside the game is in any way affected by the results (e.g., nobody will be disappointed 
if one of them breaks a promise). And because each player gets the same payoff, it won't matter whether Alice and Bob
maximize collective utility or their own personal utility. Finally, the above information is completely luminous to 
both players, and hence constitutes certain shared knoweldge. I claim that at this point the obvious strategy---to decide on a button and then both press it---is no 
longer rationally available.

For concreteness, let's suppose that Alice and Bob have agreed to press the red and blue buttons respectively. They go into their booths. 
What will Alice do? She is a perfect expected  utility maximizer. She will only press the red button if the expected
utility of doing so is at least as big as that of all the alternatives (these being being pressing the blue button or 
pressing no button). Now the expected utility of pressing the red button is only going to be at least as big as the
expected utility of pressing neither button if Alice takes it to be significantly more likely that Bob will press blue
than that Bob will press red. In the case of the above matrix, Alice needs to be at least ten times as confident
of Bob's pressing blue than of Bob's pressing red.

But why should Alice take it to be an order of magnitude more likely that Bob presses the blue button than the red button? 
Ordinary human beings take themselves to be beholden to norms of promise-keeping, and tend to abide by those norms,
especially when there is no clear benefit to failing to do so. But Bob is an extraordinary human being, a pure expected utility maximizer. Whatever
normative force he takes promises to have has to be derivable from the norm of expected utility maximization. In ordinary
contexts, dealing with ordinary human beings, keeping promises certainly does maximize utility, because ordinary human beings
believe in norms of promise-keeping, punish those who break those norms (if only by castigating or refusing to enter on
joint projects with promise-breakers), and in any case tend to abide by these norms, unless perhaps it is highly
profitable not to do so. But Alice and Bob are not dealing with ordinary human beings.

Here is one way to highlight the difficulty. Imagine that Alice and Bob are perfect utility maximizers but Bob has a perverse value theory
that in addition to common-sensical value assignments to chocolate bars and electric shocks assigns non-instrumental negative value to keeping 
promises and non-instrumental positive value to doing the very opposite of what one has promised (where the opposite
of pressing the blue button is pressing the red button, rather than just pressing nothing). In this case, if 
there is shared knowledge of the perverse value theory, it 
is more reasonable to expect Bob to press the button other than the one he promised. And now imagine instead that he 
is a perfect utility maximizer with a value theory that assigns positive value to keeping promises and non-instrumental negative value
to doing the opposite. In this case, it will be more reasonable to expect Bob to press the button he promised. But 
then the in-between case, where Bob is a perfect utility maximizer and assigns zero non-instrumental value to 
promise-keeping and promise-breaking, should be one where the probabilities of pressing the promised button and 
pressing the opposite button are approximately equal. And approximate equality is not good enough in this case---it's
too dangerous for Alice to press the button.

Of course, as a matter of contingent fact people have a preference for promise-keeping over
promise-breaking: we feel bad when we break promises and good when we have fulfilled them. Preferences enter into utilities,
and so if Alice and Bob have the standard preferences, they will have a bias in favor of promise-keeping, and if each knows the
other to have the preference, then each can take the other's preference into account, and hence each can expect the other to keep
the promise. 

But, first, this does not solve the problem when the penalty for both pressing the same button is much 
stronger than the preference for promise-keeping. In that case, unless Alice and
Bob are \textit{very} confident in the other's choice, a mere preference for promise-keeping will not be
enough to get them to press the promised button rather than pressing nothing.

Second, and more importantly, if a preference for promise-keeping is needed to solve the problem, we now have an argument that
some norm encumbent on humans requires such a preference. For if two human beings are stuck in the suboptimal 
nothing-nothing solution in the button-pressing
game, they are clearly falling short of what humans should be able to achieve---they are not acting as humans should.
And if having a preference for promise-keeping is the only way out, then humans clearly are defective when they
lack such a preference. The argument thus shows that there must be norms on human
beings that go beyond utility maximization, whether collective or individual.

The cooperative behavior in promise-keeping, thus, requires a normativity that goes beyond expected utility
maximization. Promises are perhaps the most morally-laden of our communicative behaviors, so this is not too
surprising. But the upshot of this chapter will be that what holds of promises holds of many and likely all
our other communicative behaviors. 

One may object that the button story is particularly unrealistic. The salient features are that payoffs for
both players are approximately the same, that the penalty for pressing the same button is very high, and 
that there is no benefit to one person pressing the button and the other doing nothing over neither doing
anything. These features are what make it particularly challenging to avoid the suboptimal equilibrium of
neither doing anything. Yet we can imagine such situations, and it is clearly within human rationality
to be able to resolve them. And if my argument is correct, then it follows that human rationality is more
than expected utility maximization. 

In any case, let's end this section with a story like our button story that does not involve modern technology. There are
two feuding families living in different villages. Each family has two guards who separately patrol the
area around their village. Alice and Bob are your family's guards. One day, they find out that the other
family's guards are weaker than usual due to having a cold, so that Alice and Bob can each go and beat up 
either of them. If they end up beating up both of them, this show of force will lead to the other family
suing for peace, and will end the feud---and the feud is destructive enough that it's worth ending even at
the cost of injury to two people. If they both beat up the same guard, the other will hear the sound and 
rush to your undefended village, burn down your family's fields, thereby greatly intensifying the feud. 
If one of Alice and Bob beats up one guard while the other remains on patrol, your family's fields will be 
safe, and the feud will be unchanged---the enemy will be intimidated by the attack, but will also 
be more angry, and these effects will cancel out. It should be possible for Alice and Bob to agree on which
guard each will attack and to rationally keep to their agreement.

\subsection{Arresting the regress of meaning}
Some communicative actions---speech acts or gestures---have their significance assigned through earlier communicative 
actions. Thus, sometimes one coins a word and stipulates its meaning in terms of other words, sometimes one uses gestures
to introduce a new word, and sometimes one just hopes that use in a rich enough communicative context will clarify the
meaning. But barring outlandish hypotheses such as that humans got their language from an
infinite regress of angels, we cannot suppose an infinite regress. There must be ur-communicative actions, ones which did not get
their significance from earlier communicative actions.\footnote{There is a Sellarsian objection to this. Perhaps there are 
behaviors prior to the advent of rationality that count as having communicative significance in virtue of \textit{later}
behaviors, in a kind of virtuous significance-conferring circle.??ref If so, however, then we can just count the whole circle 
of behaviors as the first ur-communicative community action.}

At the same time, there is a contigency here. While it feels natural to us to use an extended index
finger to indicate the nearest salient object approximately along the  extending from the knuckle in the direction of
the fingertip, it would be possible to have rational beings that use this gesture to indicate the third-nearest salient
object along the ray extending in the opposite direction. There is no necessary connection between the
physical behavior and its significance. We thus have a Mersenne question here: What grounds the correlation between
physical behavior and significance in ur-communicative actions?

We might try to explain the correlation in terms of the actual contingent behavior of individuals and communities
which arises by natural or social selection. Suppose, for instance, that some social animals evolve to squeak at 
a certain pitch when observing a predator, thereby warning other members of their group. Eventually, their descendants
develop rationality, but the squeaking behavior is maintained, and remains correlated with the presence of a predator, even 
though it is now under voluntary and rational control. It is plausible to say that the squeaking is now a communicative
activity whose significance is ``Predator!'' 

But this plausible claim deserves more careful examination. Rationality complicates things. Suppose Alice sees a 
predator and is considering to squeak to trigger her groupmates' defensive behavior. If Alice's squeaking and her fellows' 
defensive behavior is to be rationally chosen, the agents need reasons. The fact that their ancestors used to squeak 
when predators were present and start defensive behavior upon such squeaking is an interesting bit of pre-history,
but there does not appear to be a reason for them to imitate this quaint custom. Even if we add the fact that they
find themselves with a desire to squeak in the presence of the predator and to initiate defenses upon hearing a squeak,
these desires at most generate the very weak kinds of reasons one has to fulfill miscellaneous subrational desires rather 
than the strong kinds of reasons that one has to warn one's fellows and protect oneself and one's cmmunity. 

There is no difficulty here if Alice is the only rational one, and hence the others can be counted on to act instinctually. Alice can
then rationally squeak to trigger the instinct. Similarly, if Alice acts on instinct and the others are rational, they
can infer from her instinctive behavior that there is a predator present, as one infers fire from smoke. Likewise, if Alice thinks there is a fairly high chance that her
fellows, though rational, will simply non-rationally follow their habit and prepare themselves (rational beings don't
always act rationally), or if she knows that her fellows think there is a fairly high 
chance that Alice would find herself squeaking in the throes of instinct, there is no difficulty. The difficulty shows
up precisely when we have nothing but rationality at play.

Perhaps we can solve the problem by positing a non-rational preference for squeaking when seeing a predator and for
preparing a defense when hearing a squeak? After all, arguably, even a perfectly rational being will act in accordance
with preferences when other things are equal. 

But much as we saw in the promise case, the non-rational preference is insufficient here unless it is implausibly strong. For even if one finds oneself
with an urge to squeak in the presence of a predator, the squeak itself endangers one. Because of this, for a rational
being, a moderate preference for squeaking is not sufficient to motivate the squeak. It is only when one thinks the
squeaking will trigger defensive behavior among one's fellows that it's worth squeaking. Rational beings step back
from and evaluate the outputs of their preferences. Similarly, we may suppose that
defensive behavior is costly and inconvenient, and is only worth engaging in, notwithstanding the non-rational preference,
when there is reason to think there is an actual predator.

Instead of a brute preference, perhaps convenient priors will do. Thus, suppose that members of the community simply find
themselves with a high prior conditional probability that a member of the community rationally squeaks when presented with a 
predator and does not squeak when not presented with a predator.\footnote{I am grateful to ?? for the suggestion that
priors might do the job.} Knowing this prior is wide-spread in the community, Alice can squeak in order to 
get her fellows to update their credences in favor of a predator. The priors seem pleasantly self-confirming: if community
members have the priors, then it will become public that they do so, and the squeaking behavior will match the priors.

But now suppose Bob is reflecting on his convictions. Bob finds himself accepting a correlation between Alice's rational 
squeaks and the presence of predators. But since the squeaks are rational, there must be a rational explanation of these 
squeaks. Since we are no longer attempting a preference-based story, presumably the explanation is that Alice accepts a 
correlation between community members hearing squeaking and their rationally coming to think there is a predator. In other
words, Bob finds himself having a brute prior concerning a contingent and empirical matter---namely, another community
member having a certain credential state.  However, when we find out that our conviction about a contingent and empirical 
matter is simply a brute prior, that tends to undermine the conviction. Suppose that I find myself believing there is vast treasure buried under my house. I search
for the source of my belief, and find it's just a prior. Absent a story such as that angels put that prior in my head
to encourage me to dig out the treasure, finding out that this was \textit{just} a prior should undermine the confidence,
contrary to what subjective Bayesians think. This is why it is unstable to respond to a skeptical hypothesis by simply
citing a brute low prior for it. 

One might hope that natural selection can help. We have good reason to expect that social animals would evolve
ur-priors that enable communication. Thus, it seems these priors are not brute: they are coordinated by natural selection.
However, presumably such evolved priors would concern pre-rational behavior: they would not be priors for 
conditionals whose antecedent is that Alice or Bob is acting purely rationally and whose consequent is some
claim about their behavior, which are the relevant conditionals once Alice and Bob are acting purely rationally.

And in any case why should one think there would be any continuity between pre-rational squeaking and rational squeaking?
Exactly the same considerations as in the promise case arise here. Just as we considered the case of rational
agents who set a non-instrumental disvalue on promise-keeping, we might consider rational agents who set a
non-instrumental disvalue on acting like one would pre-rationally. Such agents' sqeaking would be counter-correlated
with danger. On the other hand, agents who place a non-instrumental value on acting like one would pre-rationally would
exhibit a positive correlation between squeaking and danger. It is seems that the in-between case where
no value is attached to acting similarly to pre-rational action should result in no correlation. Thus, for evolved
agents to function properly, we need them to have a norm by which they should prefer to maintain pre-rational 
signalling practices to some degree. 

\subsection{Requests}
Typically, one asks someone for something that one wants. But asking is not the same as communicating one's desire. First,
sometimes one asks for something one doesn't want. For instance, a security specialist could conduct phishing calls where they
ask fellow employees for their passwords, hoping that few if any will give it. Or a middle manager might be tasked by upper
management with requesting something from staff that the middle manager thinks is actually bad for the company, and hence hope
that no one will agree to the request. Conversely, one may want something but not ask for it for moral reasons. To adapt a 
situation that occurs more than once in P.~G. Wodehouse's fiction??ref, one may own an ugly heirloom that one cannot give away because 
of one's relationship with the person from whom one received it, but one would be glad if it were taken away. One could imagine
a frank conversation where one happens to intimate that one wouldn't mind having the heirloom taken away. One may suppose that
in such cases the communication \textit{is} a surreptitious request---and that, of course, is illegitimate, much as a king's
exclamation ``Would that someone rid me of this troublesome priest'' is an invitation to murder. But one could also imagine
a case where the intimation is not a coy request, but simply a frank statement to a friend, followed by sincere emphasis that one isn't
requesting removal. In that case, removal of the heirloom would be theft, even if welcomed by the owner. Or, for a
different case, one might have a moral objection to a particular life-saving medical procedure, and hence one's conscience would
forbid one from requesting it, but nonetheless wish that the procedure were done to one against one's will, say by a medical
mistake, and one could in a frank conversation communicate that wish \textit{without} that constituting an underhanded request.

In making a request, then, one not only affirms the existence of a desire, but one creates a reason for the other 
party to provide one with something. And it's not just any reason, but a special kind of reason, a reason in light of one's own request.

But now consider the first time anybody ever requested anything on earth. In requesting, they created a moral reason for their interlocutor. 
The power to create such a reason must have been a power the requester already had.  Moreover, the meaningfulness of 
the communicative act of requesting must have already been in place: the act must have been understandable, 
since requesting only creates a reason when the requesting is understandable. But how could that communicative act not only have had its illocutionary force but had been \textit{understable} as having that illocutionary 
force given that no one had ever requested anything? The meaning of a request is largely defined by the kind of reasons it gives
rise to. But how can one grasp these reasons if one has never encountered them before? It seems that we have to have
a responsiveness to such reasons in our very nature.

\subsection{Schelling focal points}
The economist Thomas Schelling??refs performed a number of experiments on coordination, in the context of 
games where two or more players make independent decisions and if these decisions are appropriately coordinated,
they both win, while if they are not coordinated, they both lose. In a paradigm example, three players are asked to
give the letters A, B and C in some order, with all of them winning if everyone gives the same order and all
of them losing otherwise. Not surprisingly, the majority would write down ``ABC''. We can call a type of behavior
that is converged on in such a way without prior communication and where we have a shared expectation of such a 
convergence a ``Schelling focal point'': writing down ``ABC'' is one, but presumably writing down ``BAC'' is not.

Now, suppose Alice and Bob have shared knowledge that in the  past squeaking by members of their kind was associated 
with danger. Alice sees the danger and needs to communicate this to Bob 
who knows that she is acting voluntarily as a pure expected utility maximizer. Let's imagine that Alice is now 
considering what auditory production
to make with three options easily available to her: squeak, stomp loudly, and maintain silence. We have
three behavior types going along with these three options: (a) in the presence of danger make the same sound as
used to be correlated in the community with the presence of danger, or (b) make a different sound in the presence
of danger when previously some sound was correlated with the danger, or (c) make no sound in the presence of 
danger where a sound was previously correlated with the danger. Of these three options, we would expect that only
(a) is a Schelling focal point. Bob would expect Alice to go for the focal point, and so if she squeaks we would
expect him to interpret her as acting in a way that correlates with danger.

But this solution fails when Alice and Bob have a shared knowledge that they are expected value maximizers
with no special non-instrumental value attached to going for focal points. The argument should now be familiar
(see ??backref).
Suppose that Alice and Bob had shared knowledge of Alice negatively valuing going for focal points. Then we
would expect that Alice's squeaking would be evidence for Bob that she is \textit{not} in danger. The evidential
force of this evidence would be expected to decrease the weaker the negative valuation of focal points.
In the case where Alice's valuation of focal points is positive, her squeak would provide evidence of danger,
with the strength of evidence co-varying with the degree of her positive valuation. And so we would expect
that in the case where Alice assigns zero non-instrumental value to going for focal points, there is zero evidence,
assuming a certainty that she is an expected value maximizer.

Of course, in practice, one may know that someone is an expected value maximizer, but not be sure of it, and in
the absence of certainty, one might reason that if Alice isn't an expected value maximizer, but one of the
\textit{hoi polloi} who squeak without engaging in expected utility calculations, then her squeak is 
evidence of danger, and so as long as there is a small chance that she isn't an expected value maximizer,
the squeak provides weak evidence of danger. But we already saw that weak evidence is not enough. 
Suppose the danger in question is a major 
flood, and the right response to such a flood is evacuation of the village. Maybe the background chance of such a
flood on any day is one in a hundred thousand, but with Alice's squeak it becomes one in ten thousand. That may
still not be enough to make a costly evacuation worthwhile. For communication to be as effective as it is for rational
beings like us, it needs to provide more than weak evidence.

That there are Schelling focal points is plausible. Indeed, the Aristotelian can plausibly say that our
nature builds in such points, though doubtless often under some general description, like ``When all else is close to
equal, prefer to put
things in the order that your community most typically enumerates them in'' rather than a specific
description like ``ABC'', and provides us with a norm whereby we should have a weak preference for going
for them. A bit of reflection shows that the points will have seemingly arbitrary parameters specifying how close to
equal should other things be, how strong should the preference be, how you should define the boundaries of your
community, and what is the function from the degree of typicality of a behavior in the community to the strength of
reason to engage in it, and hence we will have a multitude of Mersenne questions. Furthermore, the argument above
suggests that in some cases, a weak preference for Schelling focal points is not enough to ground communicative
norms, as a weak preference will not generate sufficiently strong reasons in cases where it is particularly
dangerous to have a misunderstanding.

\subsection{Communication and norms}
\subsubsection{Declarative communications}
We have seen that the transition from non-rational signalling to rational communication of a sort akin to assertion
is difficult. Thinking
about the cases of promises, assertions and requests has shown that generation of a new type of illocution is 
problematic. We need some sort of a reason-generation mechanism in our very nature connected to communicative
norms. In this section we focus on declaritive or assertion-like communications, \textit{communication that} some fact obtains.

Can we suppose that the normative mechanism here is a necessary one? Perhaps it is a necessary truth that when
there is a pre-rational behavior that tends to be triggered by circumstances $C$, then that behavior when done rationally
signifies or communicates $C$? ??refs-to-convention-literature 
But there would be multiple Mersenne questions that would be raised by such a necessary truth. First,
we need to select one item $C$ in the causes rather than another---does the squeak signify the predator, or the predator's fur, or the
light in the air between the predator's fur and the observer's eyes, or the immediate cause of the predator's presence? 
There are multiple selection rules, 
no one of them significantly more natural than \textit{all} the others. Second, what degree of reliability does the 
triggering tendency have to have in order to yield a signification fact? 
The multiplicity of parameters in the connection between behavior and
significance points to something contingent in a way that is by now familiar. 
We can easily imagine different species of rational beings where the parameters are
different from what they are in us. 

But we have already seen that Aristotelian form can solve multiple problems of providing a source for norms.
In the case of our squeakers, we can likewise suppose that the animal's essential form directly specifies that squeaking properly occurs only when there is a 
predator present, or it could specify a general rule for connecting pre-rational behavior with norms of significance. 

But even if there is such a norm-generating process, what makes the norms be norms of \textit{communication}? A cat's nature 
requires it to turn its ears towards relevant sounds. When we see a cat turn its ears in some direction, that provides us with 
evidence that there was some sound relevant to it. But the cat is not communicating that there is a sound relevant to it by
turning its ears. What, then, makes it be the case that a norm in the nature of a communicative animal is a communication-constituting
norm? Do we not need some further primitives besides norms of proper function to make it be \textit{communicative} proper function?

We can speculatively sketch a part of an answer in terms of the \textit{content} of norms. A toy story could be that 
some norms come in pairs, where one norm posits that a certain overt behavior is only proper when some fact $p$ is known to a 
community member to obtain \textit{and} another community member is known to be present and capable of observing the behavior, while 
another 
norm posits that when that overt behavior is observed in another member of the community, there is a tendency to form a belief 
in $p$. In that case, the toy story says that a behavior that is a fulfillment of the first norm counts as a communication 
of $p$ and a behavior that is a fulfillment of the second norm counts as a reception of $p$. Of course, the full story would need
to be much more complicated.

And all that said, it is not clear that we need a full story as to which exact behaviors are in fact communications. What matters
for figuring out what to do (say, in a case where a conspecific squeaks) is the 
content and force of the norm, not what kind of norm it is. It is a tautology that if the 
force of a norm is kept fixed, the norm has the same reason-giving impact on us, whether it be a norm of semantics, prudence, 
etiquette or morality.\footnote{It is worth noting here that the degree of force
of a norm raises another Mersenne question.}

\subsubsection{A speculative partial reduction of illocutionary force}
In the previous section I offered a speculative normative account of \textit{communicating that}, i.e., of declarative
or assertion-like 
communications. But communications come in types corresponding to other illocutionary forces as well. In this section, 
let's consider some of the normatively most important communications that we might call properly \textit{performative}: promises, 
commands, requests, questions, and consents. The force of each of these performatives is closely tied to a normative effect on the speaker or the audience when things go right. Thus, when things go right, a promise creates 
an obligation on the speaker to the audience, a command creates an obligation on the audience, a request or
question creates a non-obligatory reason in the audience for an action or communication, and a consent cancels a reason 
for the audience. 

Assertion seems different. While assertion is governed by norms---it is only appropriate when its content
is true, or believed or known, depending on the exact theory of the norm of assertion---it is not quite as obvious
what kind of a normative \textit{effect} it produces. A number of people have suggested that assertion does create
a \textit{prima facie} obligation to correct one's statement if one's statement turns out to be false.??ref If this is the
characteristic normative effect of assertion, assertion differs from what I called the proper performatives. For with the 
proper performatives, the characteristic normative effect is clearly the central point of the practice. But the 
obligation to correct one's statement is not \textit{central} to the practice of assertion. Note that
if there is no afterlife, it makes little sense to make a promise for tomorrow if one is clearly about to die and 
similarly it makes little sense to make a request for tomorrow of a clearly currently dying person, precisely because
the characteristic normative effect of the speech act will be irrelevant or not even come off. But even if there is 
no afterlife, it makes perfect sense to use the last moment of one's life to make an assertion, even though the
normative effect of being required to correct one's statement is irrelevant or does not come off. 

One may have some hope in thinking that assertion has a more central characteristic effect on the audience.
Perhaps it creates a \textit{prima facie} obligation to believe the asserted content, an obligation whose
violation violates the virtue of proper trust. While I am inclined to think there may be something to the
suggestion that assertion does create such an obligation, there is reason to doubt that this is exactly 
parallel to the normative effects of proper performatives. In those, the characteristic normative effect is central to the concept of the
act. Someone who does not know that a promise effects an obligation on the speaker probably can't even 
make promises and does not understand what has happened when someone made a promise.  But while there may 
be a \textit{prima facie} obligation due to the virtue of trust to believe what is asserted to one, the 
existence of this obligation does not seem as central to the practice. There seems to be no difficulty
in asserting without believing oneself to be effecting any obligation on the audience. 

Thus we have some reason to think that assertion is different from the proper performatives in that while 
it may be partly defined in normative terms, as indeed I think it is, that definition 
involves the norms governing the making of the assertion rather than the normative effect of the assertion.
Conversely, while assertion is at least partly constituted by norms governing the making of the assertion,
the special norms governing the making of the proper performatives appear derivative from the connection
to the normative effect. Thus, one shouldn't command things when one lacks the relevant authority because 
then the normative effect of the command will be lacking and yet one is apt to deceive the listener into
thinking that there is such a normative effect. Similarly, one shouldn't promise what one intends not to
do because of a general moral principle that one shouldn't intentionally put oneself in a position where 
one won't fulfill one's duties. 

Now consider the question of what a promise is---or any of the other non-assertoric speech acts we've
considered. It is not \textit{simply} an effecting of a specific normative effect. For the very same
normative effect as a promise has could be effected differently. For instance, I may acquire an obligation
to buy you a new phone by promising to do so, or by deliberately smashing your current phone. We get a 
little closer to the truth by saying that a promise is an effecting of the normative effect by communicative
means, but that's not right either. I could come to be obligated to do fifty pushups by promising someone to do so,
or by insulting a fellow soldier while being under a standing order imposing an obligation of fifty pushups whenever 
one insults a fellow soldier, and in both cases I gain the obligation by a communication.

One wants to say something like this: To promise is to gain an obligation to 
$\phi$ by communicating (or intentionally communicating or some other close variant) that one is promising 
to $\phi$. Here, as before, \textit{communicating that $p$} is either asserting $p$ or something sufficiently similar 
to asserting like intimating that $p$, squeaking with a relevant content, etc. But this account is obviously circular, since the account of promising
involves communicating that one is promising.

But an Aristotelian can hypothesize the following story. A normative effect is an effect on facts about
what normative claims are are true. Then:
\ditem{cnp}{An agent has a \textit{communicative normative power} for a normative effect $E$ in circumstances
	$C$ if the agent's normative nature is such that by communicating in $C$ that the agent is producing $E$
	precisely by intentionally communicating that they are so doing the agent succeeds in producing $E$.}
\ditem{pp}{A \textit{promissory power} with respect to an audience $x$ and an action of $\phi$ing is a 
	communicative normative power whose normative effect is the speaker's owing to $x$ that the speaker $\phi$.}
\ditem{promise}{A \textit{promise} is a successful exercise of a promissory power.}
cf.??refs

For instance, I might tell you:
\ditem{lunch}{I am hereby gaining an obligation to buy you lunch by exercising a normative power 
that produces in the speaker an obligation by communicating that they are gaining such an obligation by 
a power of that sort.} And I then become bound, because it is my nature to be bound by such an exercise
of a communicative power. Of course, in practice, we communicate the content of \dref{lunch} by using
simpler verbage, such as ``I'm hereby promising to buy you lunch'' or ``I shall buy you lunch'' or,
in countries which do not distinguish ``will'' from ``shall'', merely ``I will buy you lunch'', in a context
where it is clear that one is committing oneself rather than merely predicting the future. 

And one can similarly get accounts of commands, requests, questions, and consents by describing the normative effects.
And for each one we might suppose we have some handy shorthand. For instance in English in asking a yes-or-no question, 
instead of a complex declarative statement about the listener gaining a reason to say ``yes'' if a proposition $p$ is true
and ``no'' if it is false, one can simply say a sentence whose content is $p$ with an interrogative tone. 

On this speculative account, we have reduced ``proper'' performatives like promises, commands, requests, questions, and consents to something
assertion-like, a communication with a normative content which, in light of our shared human nature, has the
power of producing the very effect it describes, when that effect is within one's normative capabilities.
For not every normative effect is indeed within these capabilities: I cannot become bound to do something 
immoral by a promise, and a command to a random stranger to give me a dollar has no normative effect.
 
This ability to make true what one is saying may remind one of an engineer who made a robot that, within a 
range of capabilities, does what one describes it as doing when one describes it as about to do it because one says
so. Thus, to get the robot to vacuum the floor one might say: ``The robot is about to vacuum the floor because of
what I am hereby saying.''

There may, of course, be illocutionary forces beyond those of assertion-like communications and proper performatives, 
and we haven't given account of these. But it is very plausible that assertion-like communications and proper performatives are
the most important of the communications between humans. And at least some others can be straightfowardly accounted
for by a relationship to these. Thus, forms of
fictionalization or stage-acting might beaccounted for as simulations or
pretences to other kinds of speech acts.??refs

The normative account offered of assertion-like communications and proper performatives likely needs refinement.
But it gives a picture of how an Aristotelian can account for basic and central phenomena in human communication
by invoking a rich picture of norms grounded in human nature.

\section{Content and indeterminacy of reference}
Wittgenstein, Kripke, Quine and Putnam??refs have problematized reference and content in light of the fact that different
content attributions to our locutions can be made to fit with our behavior. The Wittgenstein-Kripke line of thought notes
that any finite number of cases of behavior can be made to fit with infinitely many rules. Any finite number of utterances
of ``$a+b=c$'' that fit with our ``usual'' interpretation of ``$+$'' will also fit with infinitely many rules, including,
say, the rule that ``$a+b=c$'' means that $c$ is identical with $a$ plus $b$ 
when $a$ and $b$ are less than or equal to $x$ and 
that $c$ is identical with $a$ times $b$ when at least one of $a$ and $b$ is bigger than $x$, where $x$ is some specific gigantic number. The Quinean line of thought observes that the same word, ``Gavagai'',
can be interpreted to mean a rabbit or an undetached rabbit part, with both interpretations fitting equally well with the
community's practices. And finally the Putnamian line of thought observes that a remapping of the truth conditions can make
``The cat is on the mat'' mean any other true proposition, as well as noting that the identities of mathematical objects---such as
the integers---would be underdetermined even by a countably infinite number of statements about them.??ref 

In all of these cases, we have the initial intuition that there is a well-defined meaning to the locutions, an intuition that
is destabilized by the arguments. These cases, thus, can be seen as the opposite of the cases of vague terms like ``bald'', where
our initial intuition is that there is no well-defined meaning.

We thus have two families of arguments. One family of arguments pushes in the direction of indeterminacy. And it does so not
just in the cases where indeterminacy is intuitive, as for ``bald'' and ``heap'', but alas also in cases where we expect determinacy,
as with the question whether we are referring to rabbits or undetached rabbit parts. Another family of arguments, mainly those
based on insistence on classical logic??backref, push in favor of determinacy, but alas also in cases where we expected indeterminacy.

With regard to these arguments, it would be simpler either to embrace determinacy in all cases or to embrace indeterminacy in all 
cases. For then we would only need to bite the bullet on one set of arguments. If we are to do this, then embracing determinacy in
all cases seems preferable---embracing indeterminacy about all of language would seem to do too much damage to our linguistic practices.
However, by treating all the cases alike, we go against common sense which distinguishes ``bald'' from ``rabbit''. 

The Aristotelian has a particularly good hope of having a metaphysical answer to the arguments for indeterminacy,
by grounding sharp facts of meaning in a human nature that grounds answers to a multitude of Mersenne questions.
This answer can be embraced in all cases, thereby resulting a picture of a sharp world that we will discuss below, 
or only in some cases, which fits better with common sense ``folk linguistics'' of vagueness.

All the arguments for indeterminacy that were mentioned are based on an assumption that the correct semantic theory will make semantic facts supervene on
facts about our actual behavior and the world around us. But an Aristotelian can reject this assumption, and add normative facts about humans 
to the facts about our actual behavior and the world around us as part of the supervenience base for semantics. These further
facts could be or imply hyperintensional normative
facts, such as that it is only appropriate to say ``Gavagai!''\ in the presence of a rabbit. Granted, necessarily, one is in the
presence of a rabbit if and only if one is in the presence of an undetached rabbit part. But there can still be a difference between
the norm of its being appropriate to say ``Gavagai!''\ in the presence of a rabbit and a norm of its being appropriate to say it 
in the presence of an undetached rabbit part.

Norms are very plausibly hyperintensional: $\phi$ing and $\psi$ing might be such that necessarily one does one if and only if one does the other,
but it is still a different thing to be required to $\phi$ than to be required to $\psi$. One way to see this is that if one
is required to do something, one is required to try to do it. But trying, like intending and believing, is clearly hyperintensional.
It is a different thing to try to bisect-or-trisect an angle with ruler and compass than to try to bisect an angle with ruler and 
compass, even though, necessarily, one bisects or trisects if and only if one bisects, since trisection is impossible. If I do not
know that trisection is impossible and I have promised a friend to show them a trisection or bisection, what I am obligated to try
is different than it would have been had I promised to demonstrate a bisection. 
It is one thing to have a reason to bisect and another to have a reason to bisect-or-trisect. Or, to adapt an example of 
Faroldi's (??ref:p137, Hyperintensionality
and Normativity), you might be obligated to drive to the hospital, without being obligated to either drive to the hospital or 
drive to the hospital while drunk. 

The above examples all involve moral normativity. But plausibly the same is true of other kinds of normativity. The function of the
$\times$ key on a calculator is to multiply quantities, not to calculate the exponential of the sum of their logarithms.\footnote{This is arguably
true even if in fact the code running on the calculus actually performs multiplications by exponentiating the sum of the logarithms,
as one essentially does on a sliderule.} It is 
the proper function of a duck embryo to develop two feet, but  it is not the proper function of a duck embryo to grow a
number of legs that God would believe to be the smallest prime number.

Similarly, reasons are hyperintensional, and norms give rise to reasons, which makes it likely that the norms themselves are
hyperintensional. To see that reasons are hyperintensional, note that reasons sometimes provide explanations of actions, and 
explanations are always hyperintensional.\footnote{Cf. Faroldi (p.~139)??ref. Faroldi restricts this to non-causal explanations, but
causal explanations are also hyperintensional by our argument below.}
 That explanations are hyperintensional is easiest to see in the special case of entailing
explanations, where the explanans entails the explanandum, as when the facts that Bucephalus is a horse and all 
horses are mammals explain
and entail that Bucephalus is a mammal. For if $p$ explains and entails $q$, then $p$ is equivalent to $p\And q$, but a 
conjunction does not explain its own conjunct. But if explanation were merely intensional, then anything equivalent to an 
explanation would also be an explanation. And even without entailment it is easy to see the hyperintensionality of
explanation. For suppose $p$ explains $q$. But $p$ is equivalent to
$$
(p\And q)\Or (p\And\Not q)
$$
and this complex disjunction does not explain $q$. 
For the second disjunct, namely $p\And\Not q$, does nothing to contribute to explaining $q$, and so if the complex disjunction 
explained $q$, it would do so by means of its first disjunct, $p\And q$, and that does not explain $q$ either.

A similar argument may directly show the hyperintensionality of reasons. Suppose that $p$ is a reason for $x$ to $\phi$. Then 
$$(p\And \phi(x))\Or (p\And \Not\phi(x))$$ does not seem to be a reason for $x$ to $\phi$. For, plausibly, if a disjunction is a 
reason to $\phi$, then at least one disjunct is a reason to $\phi$. But $p\And \Not\phi(x)$ is not a reason to $\phi$: that I
promised to call you by noon and failed to call by noon is a reason to apologize, not a reason to call (have called?)\ by noon! And that I $\phi$ is not 
part of a reason for me to $\phi$, so $p\And\phi(x)$ is not a reason for me to $\phi$ either.

Furthermore, an Aristotelian normative account of meaning doesn't require us to have any causal connection to the objects we speak about, and hence mathematical objects
are no more problematic than physical objects. One form of semantic indeterminacy has to do with the observation that no collection of consistent finitely specifiable first-order axioms of arithmetic is sufficient 
to determine which mathematical object we are speaking about when we talk of ``the natural numbers''. This indeterminacy
comes in two varieties. One variety is famously pointed out by Benacerraf??ref: there are many sets of abstract objects
that could just as well serve as natural numbers, none of them privileged. For instance, we might take $0=\varnothing$,
$1=\{ \varnothing \}$, $2=\{ 1 \}$, $3=\{ 2\}$, and so on. Or we could just as well take $0=\varnothing$, $1=\{ 0 \}$,
$2=\{ 0,1 \}$, $3=\{0,1,2\}$, and so on. One may not worry too much about this if all of these admittedly different
structures give rise to exactly the same truths about the naturals (e.g., in each one Fermat's Last Theorem holds).
The second variety, however, is more serious and comes from G\"odel's first incompleteness theorem. 
For any finitely characterizable and consistent collection $A$ of first-order axioms, there will be an arithmetical
sentence $g$ and a pair of natural number structures satisfying $A$ but in one of which $g$ is true and in the
other it's not. Since plausibly there is a fact of the matter as to whether any specific arithmetical sentence
is true or false, this is problematic, since our finite linguistic resources seem incapable of specifying which
natural number structures we mean in a way sufficient to determine the truth or falsity of all arithmetical sentences. (Cf.??ref:Putnam) 

Both problems can be resolved in a normative way. To resolve the first, we need only suppose that our assertions
about the natural numbers have norms of appropriateness that involve facts about a specific set of abstract objects.
For instance, we can suppose a norm that determines that 
when our language is ``number-like''---when the terms of the language play a certain kind of ``number'' or ``counting'' role---then
the language refers to a specific set of abstract objects. Any such specification of a ``number-like'' term is going
to be extremely complex, and may involve many contextual and social features, and will raise many Mersenne questions,
but as was argued in ??backref, the norms in human nature can indeed be very complex. 
And then even if a different set of abstract objects would yield a logically equivalent norm, the hyperintensionality of
norms can privilege the specific set of abstracta as the grounds of appropriateness of arithmetical statements.

This approach would immediately resolve the second problem as well. But if we don't like abstracta or if we like 
Benacerraf's own structuralist answer
to the first problem---namely, that any collection of things playing the role of natural numbers that has the 
same truths is as good as any other---we can resolve the second problem by allowing our nature to have norms
with an infinite amount of information to specify what arithmetical structure we mean. 

\section{Sharpness and levels}
\subsection{Sharpness at the second-level}\label{sec:limiting}
\subsubsection{Declarative practices and reasons}
We should all agree that it would be possible to have an assertion-like communicative practice on which a declarative utterance instead of expressing 
a specific proposition subject to classical logic, expresses a \textit{family} of propositions, and the utterance has the following
axiology: it is bad if none of the propositions is true, it is good if all of them are true, and it is neutral if some but not others are
true. We take someone to be engaging the communicative practice well (badly) to the extent that their utterances are good (bad).

We can complicate things in various ways. We might, for instance, make the family of propositions itself be fuzzy, in the technical sense that we assign
a degree (say, between zero and one) to which a given proposition is in the family. Then we might say that an utterance is maximally good provided every proposition
even partly in the family is true, and maximally bad provided every such proposition is false. But for utterances on which there is no
such unanimity in the fuzzy family, we find a way of measuring an intermediate value.  Thus, the family of propositions
corresponding to ``Alice is rich'' may contain to a high degree the proposition that she is at least a millionaire, to a low degree 
the proposition that she is at least a billionaire, and to zero degree the proposition that the sky is blue. 

Such practices are perfectly 
comprehensible within an Aristotelian framework: we can suppose that human nature makes some declarative utterances fulfill us, others
be contrary to our fulfillment, and others be indifferent to us.
I have not yet claimed that our practices are like that, just that practices like that are perfectly comprehensible.

However, in fact, it is very plausible that some of our everyday utterances are not merely epistemically vague. An inquiry into whether three rocks can make 
a heap or exactly how much money one needs to have to be rich seems a waste of time, not only because the answers are useless to us, 
but because there is no answer. In particular, it is very natural to say with the supervaluationists that there are infinitely many 
ways to make ``heap'' and ``rich'' precise, for each of which there is a well-defined answer to the question, but without such
precisification there is no answer. This fits well with the hypothesis that our everyday communicative practices are  
like the ones described above. 

Our description of the practices presupposed that there are propositions that are simply true or false, and that given the truth
values of the propositions, the values of declarative utterances---whether just bad, neutral and good, or more fine-grained ones---are thereby
determined. However are they determined sharply, definitely? Isn't it plausible that not only is it vague whether some group of four rocks is a heap, 
but one can have a grouping of rocks---say, five of them---where it's vague whether it's vague or whether it's definite that it is a heap, so that 
it's vague whether the statement ``These rocks are are a heap'' is neutral or good (or it's vague what exact value it gets).

Now the value of an utterance gives rise to reasons. If an utterance has positive value, that constitutes a reason to make the utterance.
If it has negative value, that constitutes a reason to refrain from making it. And if it has no value, then we neither get a reason to make
it nor a reason not to make it. But now recall the argument from ??backref that moral evaluation 
cannot be non-epistemically vague. If moral evaluation were more than epistemically vague, and yet we had classical logic, then the right account 
of that vagueness would be that there
are many moral concepts that fit with our usage of terms like ``is right'' and ``is wrong'', no one of which is privileged. But the 
central importance of morality to our rational lives requires privileging. Nothing can ultimately compete with moral wrongness as a reason
against an action. 

And what was true of moral concepts is \textit{a fortiori} true of reason concepts in general. Nothing can ultimately compete with \textit{reasons} in
guiding our lives. Just as we might say that the overridingness of morality is the central discovery of ethics---explicit in Socrates---the 
centrality of reasons is the central discovery of action theory. It is difficult to say more here than to bang one's fist on the table. 
The concept of a reason is not an unprivileged one among many closely similar concepts. And this undercuts the possibility of 
non-epistemic vagueness about reasons. But because of the way the good and the bad immediately give rise to reasons, it follows that
they cannot be vague either. And hence in the supervaluationist social practices described above, where declarative utterances express a 
family of precisifying propositions, there must always be sharp facts about whether the family is such that, respectively, all, none or merely some of its
members are true. In other words, vagueness must stop at the first level.

A reason-giving practice can only generate sharp reasons, since there are no other reasons. Thus if vagueness is somewhere involved in a 
reason-giving practice, that vagueness must be ``flattened out'' once reasons are generated. Depending on the details, there may be
more than one way of doing that. For instance, plausibly there is first-level vagueness about a person's height: there are multiple 
ways of measuring without any privileged one, depending on how much upward stretching is allowed, what gravity regime the measurement 
is made in (remembering that even on earth, gravitational acceleration varies about half a percent with location), whether skin flaking 
at the top of the scalp is included, etc.  A practice that rewards the ``tallest person'' (say, a Guinness World Record practice) might
generate a reason to bestow the reward on a person who is definitely the tallest, or on one who is definitely or vaguely the tallest, or
it could (likely unfairly) flatten the vague data about height into sharp facts about reasons in some more complex way, especially if
the family of precisifiers of ``$x$ is the tallest person'' comes along with a degree-of-membership function. 

In principle, any finite number of levels of vagueness could also get so flattened out. Thus, if there is second-level vagueness but no third-level
vagueness, one might specify that there is reason to give the reward to someone who is definitely definitely tallest or 
definitely vaguely tallest or vaguely definitely tallest, and to no one else. And then we have fully sharp reasons, since there will 
always be a definite fact of the matter whether there is a reason to give the reward absent third-level vagueness. In light of this,
one might think that the sharpness of reasons argument would allow declarative practices corresponding to any finite number of levels
of vagueness. A limitation of vagueness to a finite number of levels would itself be a significant result. 

However, there is reason to hold out for one level of vaguness in our declarative practices. The most plausible account of the flattening in 
our ordinary declarative practice $D$ is:
\ditem{def-declare}{There is $D$-reason to declare $p$ if and only if $p$ is definitely true.}
Thus, if the existence of a reason is a definite matter, as I have argued,
then whether $p$ is definitely true should be a definite matter. And if definiteness is definite, so is vagueness, since, definitely,
$p$ is vague if and only if neither $p$ nor $\Not p$ is definite. Thus vagueness stops at the first level.

The main competitor to \dref{def-declare} would be:
\ditem{def-declare-vague}{There is $D$-reason to declare $p$ if and only if $p$ is definitely or vaguely true.}
Given that \dref{def-declare-vague} would give us reasons to affirm evidently contradictory sentences in cases of vagueness, 
it is not very a plausible candidate for an account of the relation of $D$-reasons to truth. However, even if \dref{def-declare-vague}
were the correct account, as long as it was definitely the correct account, the sharpness of ``There is $D$-reason to declare $p$''
would imply the sharpness of ``$p$ is definitely or vaguely true''. Now, it is definitely true that 
\ditem{dv-d}{$p$ is definitely or vaguely true if and only if $\Not p$ is not definitely true.}
Hence, we would have sharpness of ``$\Not p$ is not definitely true'', and hence we would have sharpness of ``$\Not p$ is definitely
true''. But since it's definitely true that $q$ is definitely true if and only if $\Not\Not q$ is definitely true, letting $p$ be
$\Not q$, we conclude that we would have sharpness of ``$q$ is definitely true''. Since this would work for all $q$, we would again
have sharpness of definiteness and of vagueness in general.

One might try for some other flattening of vagueness profiles to reasons. But \dref{def-declare} and \dref{def-declare-vague} seem to 
be the most plausible two candidates. Thus we have good reason to stop at first level vagueness.

Finally, we might also argue for the claim that vagueness stops at the first level by thinking about the specifics of the morality of promises. If I promise
to $\phi$, and I do in fact $\phi$, then I have done morally well; if I do not in fact $\phi$, then I have done morally badly.
But what if it's vague whether I have $\phi$ed? Let's say that I have promised to cure your baldness, and because of my treatment
you have some meager tufts of hair that you didn't have, not enough to make it definite that you are non-bald and yet not enough
to make it definite that you are bald. Did I do well or badly? Well, it is very natural to say: my activity was neutral in respect
of the promise. Given a sharpness in attributions of moral goodness, badness and neutrality, and given the above plausible respective matching
of moral value with attributions of definite truth, definite falsehood and vagueness, we have good reason to think that in the case
of predicates that can figure in promises at least, we can at most have first-level vagueness---it must be sharp whether someone is
definitely bald, vaguely bald or definitely non-bald. But if we have second-level sharpness about baldness, plausibly we have 
second-level sharpness about everything.

\subsubsection{Logic}
A standard argument for full-blown epistemicism is the Sorites series.??Sorensen
Consider this argument, where the if-then statements are material conditionals.
\begin{itemize}
\item[$(P_0)$] Charles wasn't old on his first day.
\item[$(P_1)$] If Charles wasn't old on his first day, he wasn't old on his second day.
\item[$(P_2)$] If Charles wasn't old on his second day, he wasn't old on his third day.
\item[...] \ {}
\item[$(P_{26999})$] If Charles wasn't old on his 26999th day, he wasn't old on his 27000th day.
\item[$(C)$] So, Charles wasn't old on his 27000th day.
\end{itemize}

Clearly $C$ is false: a 73-year-old \textit{is} old. The argument, however, is valid by 
a sequence of $26999$ instances of \textit{modus ponens}. The only way a valid argument
can have a false conclusion is by having a false premise. Now, premise $P_0$ is clearly
true. Thus, at least one of the premises $P_n$, for $n=1,...,26999$, is false. 

Now, if $P_n$ is false for $n\ge 1$, then since $P_n$ is a material conditional, its 
antecedent is true and its consequent is false. Thus, Charles wasn't old on his $n$th
day but became old by his $(n+1)$st day. Hence, we have a one-day transition from 
young to old. And it is precisely such sharp transitions that non-epistemicist advocates
of vagueness reject as absurd.\footnote{We should assume that by ``old'' we mean something like
``calendrically old''. For we all understand such locutions as ``Alice became old the
day she found out she had lung cancer.''} Yet logic forces us to accept them.

Plausibly, logic applies to propositions, not to 
sentences of our declarative practices. If we consistently precisify the premises and conclusion
of the argument, the precisification of one premise will turn out to be false.\footnote{Only one. For if Charles is old
on a day, he's old on all subsequent days. If $P_n$ is false for $n\ge 1$, then the consequent
is false, so Charles is old on his $(n+1)$st day, and if $P_0$ is false, then Charles is old on
his first day. Either way he is old on day $m$ whenever $m>n$, and
so $P_m$ is true, since it's a material conditional with false antecedent. Thus, as soon as one
premise is false, all the subsequent ones must be true.} 

On the second-level sharpness view, we can say that $P_n$ is definitely true for small $n$,
then becomes vague (maybe somewhere around $n=22000$), and finally becomes definitely true again. 
The points at which $P_n$ becomes vague and then again definitely true are fully precise, which is 
counterintuitive, but that counterintuitiveness is less evidentially significant than the 
violation of common sense in Charles becoming old on a specific day.

If we think a sentence is bad to say when definitely false, neutral when vague, and good when
definitely true, then none of the vague $P_n$ are bad to say, but the conclusion $C$ \textit{is} bad
to say. We might think that this means that we have a case where something bad to say logically
follows from a number of things that are not bad to say, and this may seem absurd. But
it's not clear that this is absurd. For we are not here dealing in propositions, where a conjunction
of acceptable ones is also acceptable, but with sentences in a vague declarative practice. We should
not import logical intuitions that apply to propositions in thinking about the value of a declarative
practice. It may also help to see that in the case of \textit{moral} badness there is nothing particularly
paradoxical about cases where asserting a conjunction is bad but no conjunct is bad to assert. For instance,
consider the case\footnote{Not hypothetical.??ref} of a racist who writes a series of 
factually correct articles, each one about a highly immoral member of a minority group. Each
article may be such that it is not bad to write, but the oevre as a whole is racist in light of 
the tendentious selection of subject matter.	

We do, however, have a famous difficulty. Like other supervaluationist views, the account being
defended has the consequence that definitely:
\ditem{some-trans}{There exists $n$ between $0$ and $27000$ such that Charles is not old on day $n$ but is old on day $n+1$.}
At the same time, for any specific day $m$ in that range, say $m=22003$, it is \textit{not} definitely true that:
\ditem{m-trans}{Charles is not old on day $m$ is but is old on day $m+1$.}
In particular, the disjunuction of instances of \dref{m-trans} as $m$ ranges over all the numbers between $0$ and $27000$
is definitely true, but every disjunct is merely vague. This is, admittedly, counterintuitive. This counterintuitiveness
is, I suspect, tied to the fact that if we have a true disjunction of \textit{propositions}, at least one disjunct 
is true.  Furthermore, there are cases where a disjunction is definitely true, but plausibly no disjunct is. For instance,
it seems to be vague whether a hot dog is a sandwich. But it is definitely true that a hot dog is a sandwich or
not a sandwich by the Law of Excluded Middle.

\subsubsection{Some objections}
The conclusions above are counterintuitive. Intuitively, just as it sounds silly to think that on such-and-such a day it was true
to say that Charles was (chronologically) old while it wasn't true to say it a day earlier, it sounds silly to say think
that there was a precise day on which he was definitely old, while the day before he was merely vaguely old.

However, it is to be expected that our linguistic intuitions are typically more trustworthy than our metalinguistic intuitions,
since our linguistic intuitions are more important to our flourishing as social animals. Thus, our intuition that oldness 
can be vague is more to be trusted than our intuition that vagueness can be vague. We have good arguments for second-level sharpness, and
these arguments undercut the intuition.

A second objection starts like this. Communicative practices of a declarative sort that embody first-level vagueness are indeed possible. All we 
need to do is to specify the values in the way we did at the beginning of Section~\ref{sec:limiting}, so that an utterance is 
good when all the propositions in an associated family are true, bad when they are all false, and neutral otherwise. If we had
a community of perfectly sharp speakers, we could even imagine introducing such a practice, either as a sort of pleasant relaxation
(it's not fun to always have to be precise) or for practical reasons, to be engaged in at times. Suppose we have such a practice, and it
includes terms like ``hairs'' and ``scalp''. But then we could engage in this practice to introduce a new non-sharp
communicative practice. For instance, we might specify that in the new practice a predication of ``is bald'' is good when 
the person has more than 2000 hairs on their scalp, is bad when the person has fewer than 1000, and is neutral otherwise. However, 
how much filament  needs to stick out of a follicle for the follicle to count as hosting a hair itself appears to be fodder for 
first-level vagueness matter, and it can be first-level vague whether a hair is on the scalp or the upper part of the cheek.
Consequently, in the new practice we can have cases where it's vague where Jim's crinal profile falls---whether he has fewer than 
1000 hairs on the scalp, more than 2000, or in-between. And in such a case it may well be vague that it's vague whether he is bald.

Now, given the possibility of such a practice, its actuality is likely. Surely we often do extend our communicative practices,
using old---and presumably vague---terms to introduce new ones. And we do that with our vocabulary.

However, it is not clear that we can successfully institute a practice with vague values. The rules of a practice 
provide reasons for the practitioners. But if
it cannot be vague whether something is a reason for $\phi$ing, a reason against $\phi$ing, or neither, then we cannot make it
vague what the rules defining the practice are and how they apply. What we can do is at most something this. We can have a practice 
of instituting practices, where we specify a collection of ordered ``rule'' pairs $(D,E)$ where $D$ is a description of a behavior (or maybe situation) and $E$ is an in-practice evaluation, such as ``permissible'' 
or ``bad''. Our practice of instituting practices then specifies that given the rule pair $(D,E)$, then $D(b)$ is 
definitely true if and only if $b$ has $E$.
In cases where $b$ does not definitely fall under the description $D$ in any of the rules, then we can simply say that $b$ definitely
lacks all of the relevant evaluative properties. 

For instance, the rules for an oversimplified race $r$ could be $(A,W)$, $(B,T)$, and $(C,L)$, where $W$ is a win, $T$ is a tie, 
and $L$ is a loss for our (contextually specified) runner, and $A(r)$ says that $r$ is a performance that is a run with the upper body of the runner crossing the finish
line before the upper body of any other runner, $B(r)$ says that $r$ is a performance that is a run with the runner's upper body never
crossing the finish line or another runner's crossing earlier, and $C(r)$ is the denial of $A(r)$ conjoined with the denial of $B(r)$.
Now suppose that in our first-order declarative language, sentences like ``Alice's upper body crossed the finish line at $t$'' are vague
when what crossed the finish line at $t$ was a loosely attached scab on the forehead. Then in cases where Alice was ahead only by such
a scab, Alice definitely lacks a win, a tie or a loss. If a win and a tie have positive valence, while a loss has negative valences, then
we can say that Alice's performance definitely is neutral.

That all our games are in fact perfectly sharp in their values is counterintuitive. But it is hard to avoid this conclusion while holding 
on to the privileged role that reasons play in our lives that forces reasons to be sharp.

\subsubsection{A sharp world and a somewhat fuzzy language}
A broadly-held intuition is that the world is sharp but our language is fuzzy, so all the vagueness is due to our language.
There is a well-known objection to this: our language is itself a part of the world, so linguistic vagueness is still vagueness
about the world.??ref:Merricks?

The view defended above where vagueness is restricted to the first level does justice to the sharp-world--fuzzy-language intuition. 
Our declarative sentences express a range of propositions, maybe even a graded range, and that's the 
fuzziness of the language. However, the propositions in the range are themselves sharp, and the truth of the sentences is
derivative from the truth of the propositions, so ultimately the world impacts our language through the sharp end of our
practices, and the world itself can be said to be sharp. 

At the same time, the view manages to escape the objection that our language is a part of the world. The relevant part of the world
is our declarative practice. And the semantics and norms of this practice are fully sharp. There is always a definite answer to 
the question whether a given proposition is a precisification of a given declarative sentence, to what degree (if the account 
involves degrees), and what the norms governing the use of the sentence are. It can be vague whether a sentence is true, but it 
is not vague what the sentence means: it means its set of precisifiers. 

Requiring a piece of sports equipment to be between exactly $200$ and $250$ grams does not render a sports practice vague.
Similarly, the fact that the evaluative properties of our declarative language are sometimes defined in terms of ranges of propositions,
rather than individual propositions, does not make the practice itself vague. Linguistic vagueness on this view does not mean that
linguistic practice as a practice is vague. It just means, very precisely, that some of the sentences of the language express a range
of propositions. This kind of vagueness does not make the practice itself vague, and does not introduce any vagueness into the world.

On the other hand, if there were higher-level vagueness, so that sometimes it was vague whether a sentence is, say, definitely true,
the linguistic practice as such would be vague. For the practice depends normatively on whether a sentence is definitely true:
there is a practice-internal good to declaring a sentence that is definitely true which is not had when one merely declares a sentence
that is vaguely true. 
??Merricks

A closely-related intuition is that the world as it objectively is is sharp, but the world as it is relative to us is fuzzy.
Someone who accepts this intuition may insist that practice-internal values are themselves relative to us, rather than a part
of the objective furniture of the world. Again, this is a difficult line of defend given the observation that if something has
a practice-internal value for some individual $x$, then it is an objective fact about the world that it has that practice-internal 
value for $x$. 

Perhaps, however, one could read this intuition as implying that there is second-level vagueness but no third-level vagueness.
Thus, one might say that for our declaratory practice, it is not sharp whether a performance is good, neutral or bad, but 
there is some objective range of precise interpretations of that practice, and we say that a performance is definitely good 
provided it is good on all interpretations, vaguely good if good on some but not all, and definitely not good if good on none. 
What that range is, however, is an objective fact about the world. Within each interpretation, the evaluation of a performance 
will be sharp. However, there does not seem to be any significant philosophical benefit to placing the sharpness at the third-level
rather than the second. We are left with the problematic idea that the concept of a reason is subject to multiple precisifications, 
in a way that does violence to the overridingness of rationality, and besides we have a more complex view, while still requiring
an account of the third-level sharpness, which is no easier to have than an account of second-level sharpness. 
And while I have argued that the intuitions supporting first-level vagueness are on more trustworthy than those 
supporting second-level vagueness, there does not seem to be as significant a distinction between the support for
second- and third-level vagueness. Thus the benefit from allowing second-level vagueness does not seem that great.

??Ref:https://johnmacfarlane.net/fuzzy-epistemicism.pdf

\section{Neo-Aristotelian metaphysics}
The neo-Aristotelian metaphysics allows us to have a completely sharp world with our language being completely sharp, with there being
definite facts of the matter about significant and insignificant
questions: Is Alice dead yet? Is this pile a heap? Should Alice rebuke Bob publicly? Is the smashed object a car?
Is this still the ship that Theseus sailed in? Is Beethoven a better composer than Bach? Should I lower my credence in quantum
mechanics after the mildly senile retired physicist told me she just found a contradiction in it? Is a cat a dommal (where ``dommal''
is a term whose patterns of use are that users are content to call all dogs ``dommals'' and are happy to infer mammality from being
a dommal). 

Our nature \textit{could} provide us with this sharpness. First, when our statements concern normative matters, our 
form can at least partly ground the truth values. This can yield complete sharpness about all normative matters.

Second, our nature could ground the facts about the proposition expressed by and illocutionary force of each of our utterances 
by grounding the norms that specify how facts about our symbolic behavior together with facts about the non-symbolic aspects of the world attach 
propositions and illocutionary force to utterances. These rules could be very complex, and known by us only approximately and in general
terms. 

But at the same time, instead of grounding what specific proposition is expressed by each declarative utterance, our nature could 
ground facts about expressed ranges of propositions, thereby allowing declarative utterances to be vague with multiple precisifiers. Again, our nature 
can do this by fully precisely grounding our semantic norms---for, as we saw in ??backref, it is possible to have fully precise
semantic norms and yet genuine first-order vagueness. This seems to be the preferable view all things considered.

Finally, and independently of whether there is any first-level vagueness, we can ask how exactly the metaphysics grounds the norms of language? 
Obviously, it is not tenable that it is, say, written into our nature that saying ``Gift!'' should indicate a present, since then we have the 
absurd conclusion that Germans speak incorrectly when they indicate poison with ``Gift!''\footnote{I take the 
capitalization to be insignificant in speech.} While it could be that there are some symbolic gestures
that have an innate meaning---pointing, say---and then the human nature would have norms constitutive of this
meaning, it is plausible that the bulk of the relevant semantic norms are such as to yield complex conditionals 
$L_{C,S,N}$ that under circumstances $C$, a communicative action of type $S$ has normative features $N$. The 
specification of 
circumstances $C$ is likely to include details about the context,
statistical facts about the instances of $S$ and of other communicative actions, as well as historical facts about 
the development of a language. The normative features can be intrinsic features of the instance of $S$---such as
that $S$ is apt or inapt---or they can be causal features, such as that $S$ leads to an obligation to $\phi$. 

We can suppose that human nature is so complex as to directly include a vast and perhaps infinite number of $L_{C,S,N}$ facts, 
for different triples of $C$, $S$ and $N$, but it is more plausible to suppose a somewhat simpler human nature that contains
general semantic rules from which facts of the form $L_{C,S,N}$ follow. But even this somewhat simpler human
nature likely involves a large number of seemingly arbitrary parameters, answering  questions such as how 
present usage is weighted against historic usage in determining meaning, how do regularities of use in finer-grained
communities (families, towns, scholarly disciplines, etc.)\ interact with regularities of use in coarser-grained 
communities (provinces, countries, etc.),\ how is agreement on a definition weighted against actual patterns of 
use (e.g., many will say a bachelor is an unmarried man but will not be willing to classify the pope as a bachelor),
how much effect on semantics comes from the fact that a proposed meaning cuts nature less or more along the joints,
and so on. We do not know these rules except in the broadest of outlines. But at the same time, given Aristotelian
optimism, we have some hope of furthering our knowledge of them by empirically studying the semantic judgments of 
actual human beings as linguists do.

\section{Norms of assertion}
Under what conditions may we assert a proposition $p$? The literature contains a number of answers, of which the main 
three are that you (respecively) believe, justifiably believe, or know $p$.??ref\footnote{There may also be some edge cases where none 
of these seem right. For instance, suppose that you are temporarily deafened after an accident and you do not even know whether 
you still have the power of speech. You turn to a friend and try to say: ``At least I can still speak!'', and gauge from 
their reaction whether what you said was true. In that case, you don't believe or know that what you are saying is true, but 
if you do succeed in speaking, it \textit{is} guaranteed to be true, so you are not being dishonest. Handling such cases in 
an account of the norm of assertion is difficult. It is tempting to modify suggested norms to say that you believe, 
justifiably believe or know the conditional that if you succeed in asserting $p$ to your audience, then $p$ is true. But it is 
not clear that in ordinary assertions you need to have any beliefs about such complex conditionals.??ref:Pruss These complications
would only serve to strengthen my case for the presence of Mersenne problems, and so I will simplify the discussion by ignoring them.}

To a Bayesian who thinks that belief and justification always come in degrees, all three norms come with an implicit or 
explicit threshold of the credence and evidential levels at which assertion becomes appropriate. And then we have a 
Mersenne problem: what explains or grounds why the threshold is where it is.

A non-Bayesian might think that belief, justification and/or knowledge are binary distinctions that cut the epistemic 
world at the joints. If so, then it may seem that we have no Mersenne problem for assertion, and indeed the lack of the 
problem is an advantage over Bayesian approaches. However, the problem returns when we take into account the complexity
in real-life assertions. For the level of belief and/or justification needed for an assertion does in fact vary from case to 
case, depending on context and confidence markers. 

Expert witnesses speaking under oath need to be more confident of what they are asserting than friends tossing around 
ideas over a beer, with a vast amount of contextual variation in between. A realistic account of the norm of assertion 
needs to take such context into account. Furthermore, even when we keep context fixed, our tone of voice, body language (including
facial expression), and choice of wording communicates the level of confidence. While one might not be lying if one says something that one 
just barely knows with a voice communicating the kind of justified confidence that a mathematician has in theorems verified
by referees, one is violating the norms proper to asserting with that tone of voice. 

It is clear, thus, that a realistic account of the norms of assertion will have to at least involve something like functions from pairs $(C,S)$ 
where $C$ specifies the conversational context and $S$ describes the speaker-provided cues to the degrees of belief, confidence, justification 
and/or knowledge relevant to assertion. These functions are unlikely to admit of any simple mathematical expressions.
Even if we neglect the social complexities of context, speaker cues themselves involve at least the three dimensions of 
tone, body and wording, weighed together in a complex way. Yet it is clear that we have norms here---and indeed morally relevant norms---and we need an 
answer to the question of what grounds the functions involved in the norms being as they are.

It is plausible to say that the functions here are largely socially defined. The same tone of voice in one culture may 
convey confidence and in another something quite different. However, that only shifts the Mersenne problem. If previously
we were, say, trying to find a ground for a function $f$ from context-cue pairs to required degrees of belief, we now need
a grounding for the (second-order) function $g$ that assigns to a set $R$ of relevant social regularities a ``threshold function'' $f=g(R)$ 
from context-cue pairs to required degrees of belief. Slight reflection should show that our function $g$ can be expected to 
be rather complex. 

We cannot say, for instance, that the degree of confidence $f(C,S)$ required for a context-cue pair $(C,S)$ 
is the average amount of confidence in fact occurring for $(C,S)$ in a culture with regularities $R$. Presumably,
the majority of assertions in a culture are appropriate. And among the appropriate assertions, most not only meet
the required threshold of confidence for their context-cue pair, but likely exceed it at least slightly. This 
suggests that it should be at least possible in a culture that the average level of confidence for asserting in 
the case of a given context-cue pair is higher than the minimum required level, and so we cannot define the 
threshold as the average. 

We would likely be closer to correctly predicting the mark of the threshold if we set the threshold some ways below
the average, say specifying that we should be one standard deviation below the 
average level of confidence. But that would likely lead to a Mersenne problem: Why is it one standard deviation below 
the average, instead of some other statistically attractive measure, such as being at the 25th percentile level of 
actual confidences for those context-cue pairs? Furthermore, such formulas are likely to fail in a hypothetical 
society where everyone is perfectly honest, and hence always asserts at or above the required threshold of confidence.

Further complexities arise from local (spatial, temporal and other) variation in cultures, even that between neighborhoods 
in a single city. The 
sample sizes for the local regularities $R$ are likely to be small, and the function $g$ from regularities to 
threshold-functions will need to take into account both local and non-local regularities, with some sort of a weighting 
in favor of the local ones. This is likely to be quite complex, and the Mersenne question of the explanation of 
why this exactly function---doubtless with many apparently arbitrary parameters---is the one that governs our 
assertive behavior is indeed very obvious. 

The Aristotelian, however, can embrace all this messy complexity, and say that the human form specifies the function from social 
regularities to threshold-functions. 

\section{$^*$Natural numbers}
Very plausibly:
\ditem{number-truth}{any first-order statement about natural numbers and their arithmetical operations is determinately true 
or determinately false, whether or not we know its truth value.} 
But what is true of the natural numbers and their arithmetical operations will frequently be false of other sets of mathematical
entities with their operations. One may initially conclude from \dref{number-truth} that we are thus able to gain unambiguous
reference to \textit{the} natural numbers and their operations in our language or thought, and then we will have a puzzle as 
to how we manage to pick out the natural numbers from among the infinity of mathematical objects.

But that's too quick. We learn from Benacerraf??ref that the concept of \textit{the} natural numbers is dubious. Set theorists
frequently identify the sequence $0,1,2,...$ of natural numbers with the sequence of sets $\varnothing, \{\varnothing\},
\{\varnothing, \{\varnothing\}\},...$ (i.e., identify $0$ with the empty set, and then identify each number with the 
set of its predecessors). It is implausible to think that this strange set-theoretic construction captures 
\textit{the} natural numbers, but it does capture a structure that for all practical purposes behaves (with appropriately
defined operations) like them. But other sequences could be used equally well. For instance, we might 
go for the sequence of sets $\varnothing, \{\varnothing\}, \{\{\varnothing\}\},...$. Or, following Frege??ref, we might 
identify a number $n$ with the class of all sets with $n$ elements. 

Suppose we take the lesson from this to be that there is no such thing as \textit{the} natural numbers. There will still be 
``arithmetical truths'' and ``arithmetical falsehoods''. There is still no reasonable doubt about the truth of the magnificent ancient
Greek discovery that for every prime number there is a larger prime number, or that Goldbach's Conjecture that every even
number bigger than two is the sum of two primes is either true or false. It remains highly plausible that \dref{number-truth}
is correct, even if there is no such thing as \textit{the} naturals. This requires that even if we do not pick out a 
specific sequence of naturals with their arithmetical operations, our language or thought somehow manages to characterize
a ``natural number structure''---an infinite plurality of objects with appropriate arithmetical operations---with sufficient
determinacy to fix the truth value of any first-order statement about them.

But how do we do that? Taking a cue from Euclid, one might say that we characterize natural number structures by a collection
of axioms. For instance, we might think of natural numbers in terms of a ``successor'' operation, and begin by saying that every natural number has a successor and no two numbers have the same successor, and continue on through our favorite axioms, such as 
the Peano ones. The problem with this is that G\"odel's first incompleteness theorem says that any consistent recursively expressible 
axiomatic characterization that includes the obviously true Peano axioms is insufficient to determine all the truths about natural numbers, and hence will fail to yield \dref{number-truth}. For any such axiomatic characterization, there will be a pair of 
mathematical structures, $N_1$ and $N_2$, each of which satisfies the characterization, and an arithmetical statement $p$ that 
is true of $N_1$ but false of $N_2$. 

There are several known solutions to this problem. The first is to simply deny \dref{number-truth}, and allow a genuine 
indeterminacy to some arithmetic statements, which are neither true nor false. This is counterintuitive, but if we could 
ensure that only very strange arithmetical statements have that indeterminacy, it could be acceptable. Unfortunately, we 
cannot ensure this. 

Consider statements of the form
\ditem{provability}{$Q$ can be proved from $P_1,...,P_n$}
where $P_1,...,P_N$ and $Q$ 
are sentences of first order logic. Such ``provability'' statements are not particularly strange, and I think we find ourselves
with strong intuitions that for any $P_1,...,P_n$ and $Q$, there has to be a determinate fact of the matter about whether 
\dref{provability} holds. This claim seems close to the heart of the objectivity of logic. But as G\"odel famously noted, sentences
can always be encoded as numbers, and the provability relation can be encoded using arithmetic operations and quantifiers. 
As a result, \dref{provability} is equivalent to an arithmetical statement. 

Suppose now that we restrict \dref{number-truth} to arithmetical statements that are translations of provability statements.
Can we now characterize natural numbers in a finite first-order way that is sufficient to yield the truth values of these 
(translations of) provability statements? Again, the answer is negative, but the issue is more complicated. Consider some 
set $A$ of first-order recursively specifiable consistent axioms including enough axioms of arithmetic. Let $G$ be a Rosser-tweaked
G\"odel sentence for these axioms, chosen so that $G$ is a $\Sigma_1$ sentence, i.e., has only one unbounded quantifier, 
which quantifier is existential??refs. Thus, $G$ is of the form $\exists n F(n)$, where all the quantifiers in $F(n)$ are 
bounded, i.e., of the form $\exists m (m<t \And ...)$ or $\forall m(m<t \rightarrow ...)$ (where $t$ is a polynomial
in the free variables). We can now construct a Turing
machine $M_G$ which iterates through all the natural numbers $n$, and halts as soon as it gets to $F(n)$. Thus, this Turing machine
halts if and only if $G$ is true. But a statement that a specific Turing machine $M$ halts can be translated into a statement
that a certain formula $\phi_M$ of first-order logic is valid, i.e., is provable from a tautology.??ref Putting all this together,
and assuming our collection of axioms includes enough arithmetic to make the argument go, we will be able to prove from the 
axioms in question that $\phi_M$ can be proved from one's favorite tautology if and only if $G$. Since $G$ is neither 
provable nor disprovable from $A$, we thus have a provability statement that is neither provable nor disprovable
from $A$.

Thus, even if we restrict the arithmetical truths we want definite truth values of to the translations of provability
statements, we won't be able to give a recursive characterization of first-order axioms that yield the truth values.

There is, however, an Aristotelian solution to the problem. While a finite collection of first-order axioms is insufficient 
to characterize all arithmetical truths, an infinite one can easily do so (if one is really profligate, one can just include all and only the arithmetical truths among the axioms!). We already saw in previous chapters that the human form likely has a vast
dizzying collection of norms embedded in it. Why not an infinite collection? Thus, human nature could include infinitely many arithmetical norms, such as ``One should use arithmetical concepts in such a way that it is appropriate to think that $A_n$'' (or, alternately, one can have a linguistic version of this norm about what kinds of things it is appropriate to say), where $A_n$ is the $n$th of the axioms, and where the axioms $A_1,A_2,...$ are sufficient to determine the truth value of all arithmetical statements (or maybe just of all 
provability statements---i.e., all of $\Sigma_1$).

The Aristotelian solution is not the only one, of course. We might have a Platonic solution on which, \textit{pace} Benacerraf,
there really is a privileged collection of \textit{the} naturals in the Platonic heaven, distinguished from alternatives by 
something like greater ``naturalness'' in the Lewisian sense (??ref). Or we might accept causal finitism??ref,
which builds the concept of the finite---and hence of a natural number---into the metaphysics underlying causation.(??ref) 
Or we might simply suppose a ``magical'' theory of reference on which there is a special relation between the human 
mind and a certain collection of mathematical entities.cf.??refs And some think that moving to second-order logic solves the
difficulty.

Nonetheless, the present Aristotelian solution still has a certain attractiveness. Unlike the magical theory of reference, we do not need 
to posit anything new about us---just more in the way of norms. And unlike the Platonic or causal finitist solutions, the
Aristotelian solution does some justice to the intuition that mathematical terminology is stipulated by our minds---except 
that the stipulation of the axioms of natural numbers is built into the nature of the human mind, rather than merely contingent.
Furthermore, the Aristotelian solution allows for an epistemology of mathematics that is closely akin to the epistemology 
of ethics, where we know norms by having an intuitive though fallible tendency to follow them, and so a particular axiom of 
arithmetic can be accessed by our finding ourselves inclined to use arithmetical concepts in accordance with the norm encoding
the axiom.

The second-order logic solution deserves some more discussion. In a second-order logic, we allow
for quantification over predicates in addition to quantification over individuals. Arithmetic 
appropriately formulated within second-order logic then has a unique model on the standard 
semantics.??ref This seems to solve all our problems at little cost beyond allowing second-order
quantification which one might think we have good intuitive reason to allow anyway.

However, it does not. The standard semantics for second order logic interprets quantification 
over predicates in terms of quantification over all sets. But this requires a fixed ``true set theory''
for the semantics. The same problem that we faced with how our thought and language picked out the 
``true natural numbers'' returns as the problem of how our thought and language picks out the true sets,
the ones that provide the standard interpretation of the second-order logic. If, on the other hand, we 
allow for non-standard semantics for second-order quantifiers, the Henkin semantics??ref, then we lose 
the unique characterization of the natural numbers, and our old problem is unsolved. 

\section{Conclusions}
A neo-Aristotelian metaphysical picture of us as having a human nature grounding a large number of complex
norms can solve the problem of where communicative norms come from in the first place, how vagueness
is to be resolved, what grounds the norms of assertion, and perhaps can even help with foundational
questions in the philosophy of mathematics. Except perhaps for the mathematical case, in all of these cases
it is very plausible that there is a species-relativity in the relevant norms, and a vast number of 
Mersenne questions, so the neo-Aristotelian solution appears superior to a view on which the norms hold necessarily.

\chaptertail

