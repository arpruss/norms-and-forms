\def\mychapter{VII}
\input{chapterhead}
\chapter{Semantics}\label{ch:semantics}
\section{Communication and norms}
\subsection{A problem about cooperation}
??cut:squeaking is better?

There are scenarios, such as the Prisoner's Dilemma or the Tragedy of the Commons??Refs, where it is difficult 
to see how to rationally secure cooperation between agents. The following should not be one of these. You have
two agents who will each in a separate booth choose whether to press a red button or a blue button. If they both
press the same button, they each get a reward, say a chocolate bar. If they press different buttons, they 
each get a penalty, say a nasty electric shock, with the penalty outweighing the award by a significant factor, so it's better 
to get neither than to get both. If either player omits to press a button, neither gets anything, and the buttons are so 
set up that one cannot press both. Moreover, the players are allowed to confer ahead of time.

Obviously, when conferring ahead of time, they will need to decide which button to press, by rolling a fair die or
flipping a fair coin if
necessary, and then they need to go into their booths and press that button. Neither has any incentive to defect
to pressing the other button, and there is no risk in pressing a button should the other defect fail to press
anything. This is a really easy win-win game. 

But now suppose our two players, Alice and Bob, are perfect expected utility maximizers who break ties with fair coinflips, 
and the only relevant utilities are the  rewards and penalties of the game. There are no further games that 
will be played. Nobody outside the game is in any way affected by the results (e.g., nobody will be disappointed 
if one of them breaks a promise). And because each player gets the same payoff, it won't matter whether Alice and Bob
maximize collective utility or their own personal utility. Finally, the above information is completely luminous to 
both players. I claim that at this point the obvious strategy---to decide on a button and then both press it---is no 
longer rationally available.

For concreteness, let's suppose that Alice and Bob have agreed to press the red button. They go into their booths. 
What will Alice do? She is a perfect expected  utility maximizer. She will only press the red button if the expected
utility of doing so is at least as big as that of all the alternatives (these being being pressing the blue button or 
pressing no button). Now the expected utility of pressing the red button is only going to be at least as big as the
expected utility of pressing neither button if Alice takes it to be significantly more likely that Bob will press red
the button than that Bob will press the blue button.\footnote{Suppose Alice maximizes only her own utility (if she
maximizes collective utility, just double all the utilities). Suppose $x>0$ is the reward and $-y<0$ is the penalty with
$y$  bigger than $x$ by a significant factor. Then the expected utility in pressing the red button will be $\alpha x-\beta y$.
Alice will only press the button if $\alpha x-\beta y\ge 0$, i.e., if $\alpha/\beta \ge y/x$. Since $y$ is bigger
than $x$ by a significant factor, this requires $\alpha$ to be bigger than $\beta$ by a significant factor.} 

But why should Alice take it to be significantly more likes that Bob presses the red button than the blue button? 
Ordinary human beings take themselves to be beholden to norms of promise-keeping, and tend to abide by those norms,
especially when there is no obvious benefit to failing to do so. But Bob is a pure expected utility maximizer. Whatever
normative force he takes promises to have has to be derivable from the norm of expected utility maximization. In ordinary
contexts, dealing with ordinary human beings, keeping promises certainly does maximize utility, because ordinary human beings
believe in norms of promise-keeping and punish those who break those norms (if only by castigating or refusing to enter on
joint projects with promise-breakers). But Bob is not dealing with an ordinary human being. He is dealing with an expected 
utility maximizer. 

Here is one way to see the difficulty. Imagine that Alice and Bob are perfect utility maximizers with a perverse value theory
that in addition to common-sensical value assignments to chocolate bars and electric shocks assigns non-instrumental negative value to keeping 
promises and non-instrumental positive value to doing the very opposite of what one has promised. I will stipulate that pressing the button of 
the other color counts as the ``very opposite''. In this case, if there is joint knowledge of the perverse value theory, it 
is more reasonable to expect Alice and Bob to press the button other than the one they promised. And now imagine that they are 
perfect utility maximizers with a value theory that assigns positive value to keeping promises and non-instrumental negative value
to doing the opposite. In this case, it will be more reasonable to expect Alice and Bob to press the button they promised. But 
then the in-between case, where Alice and Bob are perfect utility maximizers and assign zero value to promise-keeping and
promise-breaking, should be one where the probabilities of pressing the promised button and pressing the opposite button are
equal. 

What if we suppose that the solution here is that as a matter of contingent fact people have a preference for promise-keeping over
promise-breaking: we feel bad when we break promises and good when we have fulfilled them. Preferences enter into utilities,
and so if Alice and Bob have the standard preferences, they will have a bias in favor of promise-keeping, and if each knows the
other to have the preference, then each can take the other's preference into account, and hence each can expect the other to keep
the promise. 

First, it is not clear if this solves the problem if we imagine the penalty for mismatched button presses increased so that a preference
for avoidig the penalty is an order of magnitude stronger than the preference for promise-keeping. In that case, unless Alice and
Bob are going to be very confident in the other's choice, a preference for promise-keeping will not do the job.

Second, and more importantly, if a preference for promise-keeping is needed to solve the problem, we now have an argument that
some norm encumbent on humans requires such a preference. For if two human beings are stuck in a suboptimal solution in the button-pressing
game, they are clearly falling short of what humans should be able to achieve. The argument thus shows that there must be norms on human
beings that go beyond utility maximization, whether collective or individual.

\subsection{Arresting the regress of meaning}
Some communicative actions---speech acts or gestures---have their significance assigned through earlier communicative 
actions. Thus, sometimes one coins a word and stipulates its meaning in terms of other words, sometimes one uses gestures
to introduce a new word, and sometimes one just hopes that use in a rich enough communicative context will clarify the
meaning. But barring outlandish hypotheses such as that humans got their language from aliens, who got theirs from an
infinite regress of angels, we cannot suppose an infinite regress. There must be ur-communicative actions, ones which did not get
their significance from earlier communicative actions.\footnote{There is a Sellarsian objection to this. Perhaps there are 
behaviors prior to the advent of rationality that count as having communicative significance in virtue of \textit{later}
behaviors, in a kind of virtuous significance-conferring circle.??ref If so, however, then we can just count the whole circle 
of behaviors as the first ur-communicative community action.}

At the same time, there is a contigency here. While it feels natural to us to use an extended index
finger to indicate the nearest salient object approximately along the ray extending from the knuckle in the direction of
the fingertip, it would be possible to have rational beings that use this gesture to indicate the third-nearest salient
object along the ray extending from the index finger's tip to the knuckle. There is no necessary connection between the
physical behavior and its significance. We thus have a Mersenne question here: What explains the correlation between
physical behavior and significance in ur-communicative actions?

We might try to explain the correlation in terms of the actual contingent behavior of individuals and communities
which arises by natural or social selection. Suppose, for instance, that some social animals evolve to squeak at 
a certain pitch when observing a predator, thereby warning other members of their group. Eventually, their descendants
develop rationality, but the squeaking behavior is maintained, and remains correlated with the presence of a predator, even 
though it is now under voluntary and rational control. It is plausible to say that the squeaking is now a communicative
activity whose significance is ``Predator!'' 

But this plausible claim deserves more careful examination. Rationality complicates things. Suppose Alice sees a 
predator and is considering to squeak to trigger her groupmates' defensive behavior. If Alice's squeaking and her fellows' 
defensive behavior is to be rationally chosen, the agents need reasons. The fact that their ancestors used to squeak 
when predators were present and start defensive behavior upon such squeaking is an interesting bit of pre-history,
but there does not appear to be a reason for them to imitate this quaint custom. Even if we add the fact that they
find themselves with a desire to squeak in the presence of the predator and to initiate defenses upon hearing a squeak,
these desires at most generate the very weak kinds of reasons one has to fulfill miscellaneous subrational desires rather 
than the strong kinds of reasons that one has to warn one's fellows and protect oneself and one's cmmunity. 

There is no difficulty here if Alice is the only rational one, and hence the others will act on instinct. Alice can
then rationally squeak to trigger the instinct. Similarly, if Alice acts on instinct and the others are rational, they
can infer from her instinctive behavior that there is a predator present, as one infers fire from smoke. But when both
are acting purely rationally, we have a difficulty. Likewise, if Alice thinks there is a fairly high chance that her
fellows will follow their habit and prepare themselves, or if she knows that her fellows think there is a fairly high 
chance that Alice would find herself squeaking in the throes of instinct, there is no difficulty. The difficulty shows
up when we have nothing but rationality at play.

Perhaps we can solve the problem by positing a non-rational preference for squeaking when seeing a predator and for
preparing a defense when hearing a squeak? After all, arguably, even a perfectly rational being will act in accordance
with preferences when other things are equal. 

But the non-rational preference is insufficient here unless it is implausibly strong. For even if one finds oneself
with an urge to squeak in the presence of a predator, the squeak itself endangers one. Because of this, for a rational
being, the brute preference for squeaking is not sufficient to motivate the squeak. It is only when one thinks the
squeaking will trigger defensive behavior among one's fellows that it's worth squeaking. Similarly, we may suppose that
defensive behavior is costly and inconvenient, and is only worth engaging in, not withstanding the non-rational preference,
when there is reason to think there is an actual predator.

Instead of a brute preference, perhaps convenient priors will do. Thus, suppose that members of the community simply find
themselves with a high prior conditional probability that a member of the community rationally squeaks when presented with a 
predator and does not squeak when not presented with a predator.\footnote{I am grateful to ?? for the suggestion that
priors might do the job.} Knowing about that this prior is wide-spread in the community, Alice can squeak in order to 
get her fellows to update their credences in favor of a predator. The priors seem pleasantly self-confirming: if community
members have the priors, then it will become public that they do so, and the squeaking behavior will match the priors.

But now suppose Bob is reflecting on his convictions. Bob finds himself accepting a correlation between Alice's rational 
squeaks and the presence of predators. But since the squeaks are rational, there must be a rational explanation of these 
squeaks. Since we are no longer attempting a preference-based story, presumably the explanation is that Alice accepts a 
correlation between community members hearing squeaking and their rationally coming to think there is a predator. In other
words, Bob finds himself having a brute prior concerning a contingent and empirical matter---namely, another community
member having a certain credential state.  However, when we find out that our conviction about a contingent and empirical 
matter is simply a brute prior, that tends to undermine the conviction. Suppose that I find myself believing there is vast treasure buried under my house. I search
for the source of my belief, and find it's just a prior. Absent a story such as that angels put that prior in my head
to encourage me to dig out the treasure, finding out that this was \textit{just} a prior should undermine the confidence,
contrary to what subjective Bayesians think. 

Couldn't natural selection play the angel, though? There is an adaptive advantage to correlated priors in Alice and Bob 
that make communication possible, and these priors then end up automatically matching reality. ???

\subsection{Reason-generating mechanisms}
The transition from non-rational signalling to rational communication is thus difficult to analyze. We need some sort of 
a reason-generation mechanism.

Can we suppose that the reason-generation mechanism here is a necessary one? Perhaps it is a necessary truth that when
there is a pre-rational behavior that tends to be triggered by circumstances $C$, then that behavior when done rationally
\textit{signifies} $C$? But there would be multiple Mersenne questions that would be raised by such a necessary truth. First,
we need to select one item $C$ in the chain of causes rather than another---does the squeak signify the predator's, or the
light in the air between the predator and the observer's eyes, or the immediate cause of the predator's presence? There are
multiple selection rules, no one of them significantly more natural than the others. Second, what reliability does the 
tendency have to have in order to yield a signification fact? ??more The parameters in the connection between behavior and
significance point to something contingent. We can imagine different species of rational beings where the parameters are
different from what they are in us. 

Reasons are normative entities. Thus a contingent reason-generation mechanism will, plausibly, be a mechanism for generating
norms. Aristotelian form fits well here. The form could directly specify that squeaking properly occurs only when there is a 
predator present, or it could specify a general rule for connecting pre-rational behavior with norms of significance. 

But even if there is such a norm-generating process, what makes the norms be norms of \textit{communication}? A cat's nature 
requires it to turn its ears towards relevant sounds. When we see a cat turn its ears in some direction, that provides us with 
evidence that there was some sound relevant to it. But the cat is not communicating that there is a sound relevant to it by
turning its ears. What, then, makes it be the case that a norm in the nature of a communicative animal is a communication-constituting
norm? Do we not need some further primitives besides norms of proper function to make it be \textit{communicative} proper function?

We can speculatively sketch a part of an answer in terms of the \textit{content} of norms. A toy story could be that 
some norms come in pairs, where one norm posits that a certain overt behavior is only proper when some fact $p$ is known to a 
community member to obtain and another community member is known to be present and capable of observing the behavior, and another 
norm posits that when that overt behavior is observed in another member of the community, there is a tendency to form a belief 
in $p$. In that case, the toy story says that a behavior that is a fulfillment of the first norm counts as a communication 
of $p$ and a behavior that is a fulfillment of the second norm counts as a reception of $p$. Of course, the full story would need
to be much more complicated.

And all that said, it is not clear that we need a full story as to which exact behaviors are in fact communications. What matters
for figuring out what to do is the content and force of the norms, not what kind of norms it is. It is a tautology that if the 
force of a norm is kept fixed, the norm has the same reason-giving impact on us, whether it be a norm of semantics, prudence, 
etiquette or morality. 

\subsection{Content}
\subsection{Illocutionary force and moral norms}
%% blog post on requests??

\section{Indetermincy of referene}
Wittgenstein, Kripke, Quine and Putnam??refs have problematized reference and content in light of the fact that different
content attributions to our locutions can be made to fit with our behavior. The Wittgenstein-Kripke line of thought notes
that any finite number of cases of behavior can be made to fit with infinitely many rules. Any finite number of utterances
of ``$a+b=c$'' that fit with our ``usual'' interpretation of ``$+$'' will also fit with infinitely many rules, including,
say, the rule that ``$a+b=c$'' means that $c$ is identical with $a$ plus $b$ when $a$ and $b$ are less than or equal to $x$ and 
means that $c$ is identical with $a$ times $b$ when at least one of $a$ and $b$ is bigger than $x$, where $x$ is the largest
number we have ever discussed in the context of ``$+$''. The Quinean line of thought observes that the same word, ``Gavagai'',
can be interpreted to mean a rabbit or an undetached rabbit part, with both interpretations fitting equally well with the
community's practices. And finally the Putnamian line of thought observes that a remapping of the truth conditions can make
``The cat is on the mat'' mean any other true proposition, as well as noting that the identities of mathematical objects---such as
the integers---would be underdetermined even by a countably infinite number of statements about them.??ref

In all of these cases, we have the initial intuition that there is a well-defined meaning to the locutions, an intuition that
is destabilized by the arguments. These cases, thus, can be seen as the opposite of the cases of vague terms like ``bald'', where
our initial intuition is that there is no well-defined meaning.

\section{A sharp world}
%https://johnmacfarlane.net/fuzzy-epistemicism.pdf


\chaptertail

